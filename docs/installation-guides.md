# Databricks MCP Server - Detailed Installation Guides

Complete setup instructions for all major MCP clients and development environments.

> **ì–¸ì–´ / Language**: [í•œêµ­ì–´](#í•œêµ­ì–´-ê°€ì´ë“œ) | [English](#english-guide)

---

## í•œêµ­ì–´ ê°€ì´ë“œ

ì´ ê°€ì´ë“œëŠ” Databricks MCP ì„œë²„ë¥¼ ë‹¤ì–‘í•œ MCP í´ë¼ì´ì–¸íŠ¸ì—ì„œ ì„¤ì •í•˜ëŠ” ë°©ë²•ì„ ìƒì„¸í•˜ê²Œ ì„¤ëª…í•©ë‹ˆë‹¤.

### ëª©ì°¨
- [ì‚¬ì „ ì¤€ë¹„ì‚¬í•­](#ì‚¬ì „-ì¤€ë¹„ì‚¬í•­)
- [1. Claude Desktop](#1-claude-desktop)
- [2. Claude Code (CLI)](#2-claude-code-cli)
- [3. Cursor IDE](#3-cursor-ide)
- [4. Cline (VS Code í™•ì¥)](#4-cline-vs-code-í™•ì¥)
- [5. Continue (VS Code í™•ì¥)](#5-continue-vs-code-í™•ì¥)
- [6. Zed Editor](#6-zed-editor)
- [7. Windsurf IDE](#7-windsurf-ide)
- [8. OpenAI Codex (CLI)](#8-openai-codex-cli)
- [9. Dify](#9-dify)
- [10. n8n](#10-n8n)
- [ë¬¸ì œ í•´ê²°](#ë¬¸ì œ-í•´ê²°-korean)

---

### ì‚¬ì „ ì¤€ë¹„ì‚¬í•­

ëª¨ë“  í´ë¼ì´ì–¸íŠ¸ ì„¤ì •ì„ ì‹œì‘í•˜ê¸° ì „ì— ë‹¤ìŒì„ ì¤€ë¹„í•´ì•¼ í•©ë‹ˆë‹¤:

#### 1. Python í™˜ê²½ (ê¶Œì¥)
```bash
# Python 3.10 ì´ìƒ í™•ì¸
python --version

# uv ì„¤ì¹˜ (ê¶Œì¥ ë°©ë²•)
# macOS/Linux
curl -LsSf https://astral.sh/uv/install.sh | sh

# Windows (PowerShell)
powershell -c "irm https://astral.sh/uv/install.ps1 | iex"
```

#### 2. Databricks ì¸ì¦ ì •ë³´
ë‹¤ìŒ ì¤‘ í•˜ë‚˜ë¥¼ ì¤€ë¹„í•˜ì„¸ìš”:

**ì˜µì…˜ A: OAuth U2M (ê¶Œì¥ - ê°œë°œìš©)**
- Databricks ì›Œí¬ìŠ¤í˜ì´ìŠ¤ URL
- OAuth ìë™ ì¸ì¦ (ì²« ì‹¤í–‰ ì‹œ ë¸Œë¼ìš°ì € ì—´ë¦¼)

**ì˜µì…˜ B: Personal Access Token (PAT)**
1. Databricks ì›Œí¬ìŠ¤í˜ì´ìŠ¤ ë¡œê·¸ì¸
2. ìš°ì¸¡ ìƒë‹¨ ì‚¬ìš©ì ë©”ë‰´ â†’ Settings
3. Developer â†’ Access tokens
4. "Generate new token" í´ë¦­
5. í† í° ë³µì‚¬ ë° ì•ˆì „í•˜ê²Œ ë³´ê´€

**ì˜µì…˜ C: Service Principal (í”„ë¡œë•ì…˜ìš©)**
- Client ID
- Client Secret
- Account Adminì—ê²Œ ìš”ì²­í•˜ì—¬ ìƒì„±

#### 3. Databricks ì›Œí¬ìŠ¤í˜ì´ìŠ¤ URL í™•ì¸
```
AWS:   https://your-workspace.cloud.databricks.com
Azure: https://adb-<workspace-id>.<random>.azuredatabricks.net
GCP:   https://<workspace-id>.gcp.databricks.com
```

#### 4. Account API ì„¤ì • (ì„ íƒì‚¬í•­)

**Account-level ì‘ì—…ì´ í•„ìš”í•œ ê²½ìš°ë§Œ ì„¤ì •:**

Account APIë¥¼ ì‚¬ìš©í•˜ë©´ ë‹¤ìŒ ì‘ì—…ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤:
- ì—¬ëŸ¬ ì›Œí¬ìŠ¤í˜ì´ìŠ¤ ê´€ë¦¬
- ì‚¬ìš©ì ë° ê·¸ë£¹ ê´€ë¦¬
- ì›Œí¬ìŠ¤í˜ì´ìŠ¤ ìƒì„±/ì‚­ì œ
- ê³„ì • ìˆ˜ì¤€ ê¶Œí•œ ê´€ë¦¬

**í•„ìˆ˜ ì •ë³´:**
- `DATABRICKS_ACCOUNT_ID`: Account ID (UUID í˜•ì‹)
- `DATABRICKS_ACCOUNT_HOST`:
  - AWS/GCP: `https://accounts.cloud.databricks.com`
  - Azure: `https://accounts.azuredatabricks.net`

**Account ID í™•ì¸ ë°©ë²•:**
1. Databricks Account Console ì ‘ì†
2. ìš°ì¸¡ ìƒë‹¨ í”„ë¡œí•„ â†’ Account Settings
3. Account ID ë³µì‚¬

**ê¶Œí•œ ìš”êµ¬ì‚¬í•­:**
- Account Admin ì—­í•  í•„ìš”
- ë˜ëŠ” Service Principalì— Account Admin ê¶Œí•œ ë¶€ì—¬

**ğŸ’¡ íŒ**: Workspace-level ì‘ì—…ë§Œ í•„ìš”í•˜ë©´ Account API ì„¤ì •ì€ ê±´ë„ˆë›°ì–´ë„ ë©ë‹ˆë‹¤.

---

### 1. Claude Desktop

Claude Desktopì€ Anthropicì˜ ê³µì‹ ë°ìŠ¤í¬í†± ì• í”Œë¦¬ì¼€ì´ì…˜ìœ¼ë¡œ, MCP ì„œë²„ë¥¼ ê°€ì¥ ì‰½ê²Œ ì„¤ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

#### 1.1 ì„¤ì • íŒŒì¼ ìœ„ì¹˜

**macOS:**
```bash
~/Library/Application Support/Claude/claude_desktop_config.json
```

**Windows:**
```
%APPDATA%\Claude\claude_desktop_config.json
```

#### 1.2 ì„¤ì • íŒŒì¼ ì—´ê¸°

**ë°©ë²• 1: Claude Desktop UI ì‚¬ìš©**
1. Claude Desktop ì‹¤í–‰
2. Settings (ì„¤ì •) ì—´ê¸°
3. Developer íƒ­ ì„ íƒ
4. "Edit Config" ë²„íŠ¼ í´ë¦­

**ë°©ë²• 2: ì§ì ‘ íŒŒì¼ í¸ì§‘**
```bash
# macOS
open ~/Library/Application\ Support/Claude/claude_desktop_config.json

# Windows (ë©”ëª¨ì¥)
notepad %APPDATA%\Claude\claude_desktop_config.json
```

#### 1.3 ê¸°ë³¸ ì„¤ì • (OAuth)

```json
{
  "mcpServers": {
    "databricks": {
      "command": "uvx",
      "args": ["databricks-mcp"],
      "env": {
        "DATABRICKS_HOST": "https://your-workspace.cloud.databricks.com",
        "DATABRICKS_AUTH_TYPE": "oauth-u2m"
      }
    }
  }
}
```

#### 1.4 PAT ì‚¬ìš© ì„¤ì •

```json
{
  "mcpServers": {
    "databricks": {
      "command": "uvx",
      "args": ["databricks-mcp"],
      "env": {
        "DATABRICKS_HOST": "https://your-workspace.cloud.databricks.com",
        "DATABRICKS_TOKEN": "dapi1234567890abcdef..."
      }
    }
  }
}
```

#### 1.5 Service Principal ì„¤ì • (í”„ë¡œë•ì…˜)

```json
{
  "mcpServers": {
    "databricks": {
      "command": "uvx",
      "args": ["databricks-mcp"],
      "env": {
        "DATABRICKS_HOST": "https://your-workspace.cloud.databricks.com",
        "DATABRICKS_CLIENT_ID": "your-service-principal-client-id",
        "DATABRICKS_CLIENT_SECRET": "your-service-principal-secret"
      }
    }
  }
}
```

#### 1.6 ì—¬ëŸ¬ ì›Œí¬ìŠ¤í˜ì´ìŠ¤ ì„¤ì •

```json
{
  "mcpServers": {
    "databricks-prod": {
      "command": "uvx",
      "args": ["databricks-mcp"],
      "env": {
        "DATABRICKS_HOST": "https://prod-workspace.cloud.databricks.com",
        "DATABRICKS_TOKEN": "dapi_prod_token..."
      }
    },
    "databricks-dev": {
      "command": "uvx",
      "args": ["databricks-mcp"],
      "env": {
        "DATABRICKS_HOST": "https://dev-workspace.cloud.databricks.com",
        "DATABRICKS_AUTH_TYPE": "oauth-u2m"
      }
    }
  }
}
```

#### 1.7 Account API ì„¤ì • (Account-level ì‘ì—…ìš©)

**Account APIë¥¼ ì‚¬ìš©í•˜ë ¤ë©´** (ì‚¬ìš©ì ê´€ë¦¬, ì›Œí¬ìŠ¤í˜ì´ìŠ¤ ê´€ë¦¬ ë“±):

```json
{
  "mcpServers": {
    "databricks": {
      "command": "uvx",
      "args": ["databricks-mcp"],
      "env": {
        "DATABRICKS_HOST": "https://your-workspace.cloud.databricks.com",
        "DATABRICKS_AUTH_TYPE": "oauth-u2m",
        "DATABRICKS_ACCOUNT_ID": "12345678-90ab-cdef-1234-567890abcdef",
        "DATABRICKS_ACCOUNT_HOST": "https://accounts.cloud.databricks.com"
      }
    }
  }
}
```

**í•„ìˆ˜ í™˜ê²½ ë³€ìˆ˜:**
- `DATABRICKS_ACCOUNT_ID`: Databricks Account ID (Account Consoleì—ì„œ í™•ì¸)
- `DATABRICKS_ACCOUNT_HOST`: Account API í˜¸ìŠ¤íŠ¸
  - AWS/GCP: `https://accounts.cloud.databricks.com`
  - Azure: `https://accounts.azuredatabricks.net`

**Account ID í™•ì¸ ë°©ë²•:**
1. Databricks Account Console ë¡œê·¸ì¸
2. ìš°ì¸¡ ìƒë‹¨ í”„ë¡œí•„ â†’ Account Settings
3. Account ID ë³µì‚¬

**ì‚¬ìš© ê°€ëŠ¥í•œ Account-level ë„êµ¬:**
- `list_account_workspaces` - ëª¨ë“  ì›Œí¬ìŠ¤í˜ì´ìŠ¤ ëª©ë¡
- `create_workspace` - ìƒˆ ì›Œí¬ìŠ¤í˜ì´ìŠ¤ ìƒì„±
- `list_account_users` - ê³„ì • ì‚¬ìš©ì ê´€ë¦¬
- `assign_workspace_permissions` - ì›Œí¬ìŠ¤í˜ì´ìŠ¤ ê¶Œí•œ í• ë‹¹

âš ï¸ **ê¶Œí•œ ìš”êµ¬ì‚¬í•­**: Account Admin ê¶Œí•œ í•„ìš”

#### 1.8 ì„¤ì • ì ìš© ë° í™•ì¸

1. ì„¤ì • íŒŒì¼ ì €ì¥
2. Claude Desktop **ì™„ì „íˆ ì¢…ë£Œ** (Cmd+Q / Alt+F4)
3. Claude Desktop ì¬ì‹œì‘
4. ìƒˆ ëŒ€í™” ì‹œì‘
5. ì…ë ¥ì°½ í•˜ë‹¨ì— **ğŸ”¨ ì•„ì´ì½˜** (MCP ì„œë²„ í‘œì‹œ) í™•ì¸
6. ì•„ì´ì½˜ í´ë¦­í•˜ì—¬ "databricks" ì„œë²„ í™œì„± ìƒíƒœ í™•ì¸

#### 1.9 ì²« ì‹¤í–‰ (OAuth ì‚¬ìš© ì‹œ)

OAuth ì¸ì¦ì„ ì‚¬ìš©í•˜ëŠ” ê²½ìš°:
1. ì²˜ìŒ MCP ë„êµ¬ ì‚¬ìš© ì‹œ ë¸Œë¼ìš°ì € ì°½ì´ ìë™ìœ¼ë¡œ ì—´ë¦½ë‹ˆë‹¤
2. Databricksì— ë¡œê·¸ì¸
3. "Authorize" í´ë¦­
4. ë¸Œë¼ìš°ì € íƒ­ ë‹«ê¸°
5. Claude Desktopìœ¼ë¡œ ëŒì•„ê°€ì„œ ê³„ì† ì‚¬ìš©

#### 1.10 í…ŒìŠ¤íŠ¸

Claude Desktopì—ì„œ ë‹¤ìŒê³¼ ê°™ì´ ìš”ì²­í•´ë³´ì„¸ìš”:

```
"List all my Databricks clusters"
"Show me the tables in my Unity Catalog"
"Execute this SQL: SELECT * FROM samples.nyctaxi.trips LIMIT 10"
```

---

### 2. Claude Code (CLI)

Claude CodeëŠ” í„°ë¯¸ë„ì—ì„œ ì‚¬ìš©í•˜ëŠ” Anthropicì˜ CLI ë„êµ¬ì…ë‹ˆë‹¤.

#### 2.1 ì„¤ì • íŒŒì¼ ìœ„ì¹˜

**ëª¨ë“  í”Œë«í¼:**
```bash
~/.config/claude/config.json
```

#### 2.2 ì„¤ì • íŒŒì¼ ìƒì„±/í¸ì§‘

```bash
# ë””ë ‰í† ë¦¬ ìƒì„±
mkdir -p ~/.config/claude

# íŒŒì¼ í¸ì§‘
nano ~/.config/claude/config.json
# ë˜ëŠ”
code ~/.config/claude/config.json
# ë˜ëŠ”
vim ~/.config/claude/config.json
```

#### 2.3 ê¸°ë³¸ ì„¤ì •

```json
{
  "mcpServers": {
    "databricks": {
      "command": "uvx",
      "args": ["databricks-mcp"],
      "env": {
        "DATABRICKS_HOST": "https://your-workspace.cloud.databricks.com",
        "DATABRICKS_AUTH_TYPE": "oauth-u2m"
      }
    }
  }
}
```

#### 2.4 .databrickscfg í”„ë¡œíŒŒì¼ ì‚¬ìš©

ì´ë¯¸ Databricks CLIë¥¼ ì‚¬ìš©í•˜ê³  ìˆë‹¤ë©´, ê¸°ì¡´ ì„¤ì •ì„ ì¬ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

```json
{
  "mcpServers": {
    "databricks": {
      "command": "uvx",
      "args": ["databricks-mcp"],
      "env": {
        "DATABRICKS_CONFIG_PROFILE": "production"
      }
    }
  }
}
```

`~/.databrickscfg` íŒŒì¼:
```ini
[production]
host = https://prod-workspace.cloud.databricks.com
token = dapi...

[development]
host = https://dev-workspace.cloud.databricks.com
auth_type = oauth-u2m
```

#### 2.5 í…ŒìŠ¤íŠ¸

```bash
# Claude Code ì‹¤í–‰
claude

# í”„ë¡¬í”„íŠ¸ì—ì„œ í…ŒìŠ¤íŠ¸
> List my Databricks clusters
> Show tables in catalog 'main'
```

---

### 3. Cursor IDE

CursorëŠ” AI ê¸°ëŠ¥ì´ í†µí•©ëœ ì½”ë“œ ì—ë””í„°ì…ë‹ˆë‹¤.

#### 3.1 ì„¤ì • íŒŒì¼ ìœ„ì¹˜

**í”„ë¡œì íŠ¸ë³„ ì„¤ì • (ê¶Œì¥):**
```
your-project/.cursor/mcp.json
```

**ì „ì—­ ì„¤ì •:**
```
~/.cursor/mcp.json
```

#### 3.2 UIë¥¼ í†µí•œ ì„¤ì •

1. Cursor ì‹¤í–‰
2. `Cmd+,` (macOS) ë˜ëŠ” `Ctrl+,` (Windows/Linux) - ì„¤ì • ì—´ê¸°
3. "Developer" ì„¹ì…˜ ì°¾ê¸°
4. "Edit Config" í´ë¦­
5. "MCP Tools" ì„ íƒ
6. "Add Custom MCP" í´ë¦­

#### 3.3 ìˆ˜ë™ ì„¤ì • íŒŒì¼ ìƒì„±

**í”„ë¡œì íŠ¸ë³„ ì„¤ì •:**
```bash
# í”„ë¡œì íŠ¸ ë£¨íŠ¸ì—ì„œ
mkdir -p .cursor
nano .cursor/mcp.json
```

**ê¸°ë³¸ ì„¤ì •:**
```json
{
  "mcpServers": {
    "databricks": {
      "command": "uvx",
      "args": ["databricks-mcp"],
      "env": {
        "DATABRICKS_HOST": "https://your-workspace.cloud.databricks.com",
        "DATABRICKS_AUTH_TYPE": "oauth-u2m"
      }
    }
  }
}
```

#### 3.4 í™˜ê²½ ë³€ìˆ˜ ì„¤ì • (ë¯¼ê° ì •ë³´)

í† í°ì„ ì„¤ì • íŒŒì¼ì— ì§ì ‘ ì €ì¥í•˜ì§€ ì•Šìœ¼ë ¤ë©´:

```json
{
  "mcpServers": {
    "databricks": {
      "command": "uvx",
      "args": ["databricks-mcp"],
      "env": {
        "DATABRICKS_HOST": "https://your-workspace.cloud.databricks.com",
        "DATABRICKS_TOKEN": "${DATABRICKS_TOKEN}"
      }
    }
  }
}
```

ê·¸ë¦¬ê³  í™˜ê²½ ë³€ìˆ˜ ì„¤ì •:
```bash
# ~/.bashrc ë˜ëŠ” ~/.zshrc
export DATABRICKS_TOKEN="dapi..."
```

#### 3.5 ì›í´ë¦­ ì„¤ì¹˜ (Cursor ë‚´ì¥ ê¸°ëŠ¥)

Cursorì˜ ìµœì‹  ë²„ì „ì€ MCP ì„œë²„ ë§ˆì¼“í”Œë ˆì´ìŠ¤ë¥¼ ì œê³µí•©ë‹ˆë‹¤:

1. Cursorì—ì„œ `Cmd+K` (AI ì±„íŒ… ì—´ê¸°)
2. MCP ì•„ì´ì½˜ í´ë¦­
3. "Browse MCP Servers" ì„ íƒ
4. "databricks-mcp" ê²€ìƒ‰
5. "Install" í´ë¦­ (ì‚¬ìš© ê°€ëŠ¥í•œ ê²½ìš°)

#### 3.6 ì¤‘ìš” ì œí•œì‚¬í•­

âš ï¸ **í˜„ì¬ CursorëŠ” ì²˜ìŒ 40ê°œì˜ ë„êµ¬ë§Œ ì—ì´ì „íŠ¸ì— ì „ë‹¬í•©ë‹ˆë‹¤.**

Databricks MCPëŠ” 82ê°œì˜ ë„êµ¬ë¥¼ ì œê³µí•˜ë¯€ë¡œ, í•„ìš”ì— ë”°ë¼ ì„œë²„ë¥¼ í™œì„±í™”/ë¹„í™œì„±í™”í•´ì•¼ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

#### 3.7 ì„¤ì • í™•ì¸

1. Cursor ì¬ì‹œì‘
2. AI ì±„íŒ… ì—´ê¸° (`Cmd+K`)
3. MCP ì•„ì´ì½˜ í™•ì¸ (í™œì„±í™” ì‹œ ë…¹ìƒ‰)
4. í…ŒìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸:
```
@databricks list my clusters
```

---

### 4. Cline (VS Code í™•ì¥)

Clineì€ VS Codeë¥¼ ìœ„í•œ ê°•ë ¥í•œ AI ì½”ë”© ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.

#### 4.1 Cline ì„¤ì¹˜

1. VS Code ì—´ê¸°
2. Extensions (í™•ì¥) íŒ¨ë„ ì—´ê¸° (`Cmd+Shift+X`)
3. "Cline" ê²€ìƒ‰
4. "Install" í´ë¦­

#### 4.2 MCP ì„œë²„ ì„¤ì • ì ‘ê·¼

**ë°©ë²• 1: Cline UI ì‚¬ìš©**
1. VS Codeì—ì„œ Cline íŒ¨ë„ ì—´ê¸°
2. ìƒë‹¨ ë„¤ë¹„ê²Œì´ì…˜ ë°”ì—ì„œ "MCP Servers" ì•„ì´ì½˜ í´ë¦­
3. "Installed" íƒ­ ì„ íƒ
4. í•˜ë‹¨ì˜ "Configure MCP Servers" ë²„íŠ¼ í´ë¦­

**ë°©ë²• 2: ì„¤ì • íŒŒì¼ ì§ì ‘ í¸ì§‘**
```bash
# VS Code ì„¤ì • ë””ë ‰í† ë¦¬
code ~/.vscode/extensions/cline/mcp_settings.json
```

#### 4.3 ê¸°ë³¸ ì„¤ì •

```json
{
  "mcpServers": {
    "databricks": {
      "command": "uvx",
      "args": ["databricks-mcp"],
      "env": {
        "DATABRICKS_HOST": "https://your-workspace.cloud.databricks.com",
        "DATABRICKS_AUTH_TYPE": "oauth-u2m"
      },
      "disabled": false,
      "alwaysAllow": []
    }
  }
}
```

#### 4.4 ìë™ ìŠ¹ì¸ ì„¤ì •

íŠ¹ì • ë„êµ¬ë¥¼ ìë™ìœ¼ë¡œ ìŠ¹ì¸í•˜ë ¤ë©´:

```json
{
  "mcpServers": {
    "databricks": {
      "command": "uvx",
      "args": ["databricks-mcp"],
      "env": {
        "DATABRICKS_HOST": "https://your-workspace.cloud.databricks.com",
        "DATABRICKS_TOKEN": "dapi..."
      },
      "disabled": false,
      "alwaysAllow": [
        "list_clusters",
        "get_cluster",
        "list_jobs",
        "list_tables"
      ]
    }
  }
}
```

#### 4.5 Transport íƒ€ì…

Clineì€ ë‘ ê°€ì§€ ì „ì†¡ ë°©ì‹ì„ ì§€ì›í•©ë‹ˆë‹¤:

**STDIO (ë¡œì»¬ í”„ë¡œì„¸ìŠ¤):**
```json
{
  "mcpServers": {
    "databricks": {
      "command": "uvx",
      "args": ["databricks-mcp"],
      "env": { ... }
    }
  }
}
```

**SSE (ì›ê²© HTTP):**
```json
{
  "mcpServers": {
    "databricks-remote": {
      "url": "https://your-mcp-server.com/sse",
      "headers": {
        "Authorization": "Bearer your-token"
      }
    }
  }
}
```

#### 4.6 ì—¬ëŸ¬ ì›Œí¬ìŠ¤í˜ì´ìŠ¤ ì„¤ì •

```json
{
  "mcpServers": {
    "databricks-production": {
      "command": "uvx",
      "args": ["databricks-mcp"],
      "env": {
        "DATABRICKS_HOST": "https://prod.cloud.databricks.com",
        "DATABRICKS_TOKEN": "dapi_prod..."
      },
      "disabled": false
    },
    "databricks-staging": {
      "command": "uvx",
      "args": ["databricks-mcp"],
      "env": {
        "DATABRICKS_HOST": "https://staging.cloud.databricks.com",
        "DATABRICKS_TOKEN": "dapi_staging..."
      },
      "disabled": true
    }
  }
}
```

#### 4.7 ì„¤ì • í™•ì¸

1. VS Code ì¬ì‹œì‘ ë˜ëŠ” Cline ë¦¬ë¡œë“œ
2. Cline íŒ¨ë„ì—ì„œ MCP Servers ì•„ì´ì½˜ í´ë¦­
3. "databricks" ì„œë²„ê°€ í™œì„±í™”ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
4. ë…¹ìƒ‰ ìƒíƒœ í‘œì‹œê¸° í™•ì¸

#### 4.8 í…ŒìŠ¤íŠ¸

Cline ì±„íŒ…ì—ì„œ:
```
Can you list all my Databricks clusters using the MCP server?
Show me tables in the 'main' catalog
```

---

### 5. Continue (VS Code í™•ì¥)

ContinueëŠ” ë‹¤ì–‘í•œ LLMì„ ì§€ì›í•˜ëŠ” VS Code AI ì½”ë”© ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.

#### 5.1 Continue ì„¤ì¹˜

1. VS Code ì—´ê¸°
2. Extensions íŒ¨ë„ (`Cmd+Shift+X`)
3. "Continue" ê²€ìƒ‰
4. "Install" í´ë¦­

#### 5.2 ì„¤ì • íŒŒì¼ ìœ„ì¹˜

**ì‘ì—… ê³µê°„ë³„:**
```
.continue/mcpServers/
```

**ì „ì—­:**
```
~/.continue/mcpServers/
```

#### 5.3 ì„¤ì • íŒŒì¼ ìƒì„±

**ì‘ì—… ê³µê°„ì—ì„œ:**
```bash
# í”„ë¡œì íŠ¸ ë£¨íŠ¸ì—ì„œ
mkdir -p .continue/mcpServers
cd .continue/mcpServers
```

**YAML í˜•ì‹ìœ¼ë¡œ ìƒì„±:**
```bash
nano databricks-mcp.yaml
```

#### 5.4 YAML ì„¤ì • ì˜ˆì œ

```yaml
mcpServers:
  - name: Databricks MCP
    command: uvx
    args:
      - databricks-mcp
    env:
      DATABRICKS_HOST: https://your-workspace.cloud.databricks.com
      DATABRICKS_AUTH_TYPE: oauth-u2m
```

#### 5.5 JSON ì„¤ì • ì˜ˆì œ (ëŒ€ì•ˆ)

Claude Desktopì´ë‚˜ Cursorì˜ ì„¤ì •ì„ ì¬ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

```bash
# Claude Desktop ì„¤ì • ë³µì‚¬
cp ~/Library/Application\ Support/Claude/claude_desktop_config.json \
   .continue/mcpServers/databricks.json
```

ë˜ëŠ” ì§ì ‘ ìƒì„±:
```json
{
  "mcpServers": {
    "databricks": {
      "command": "uvx",
      "args": ["databricks-mcp"],
      "env": {
        "DATABRICKS_HOST": "https://your-workspace.cloud.databricks.com",
        "DATABRICKS_TOKEN": "dapi..."
      }
    }
  }
}
```

#### 5.6 ë³µì¡í•œ ì„¤ì • ì˜ˆì œ

```yaml
mcpServers:
  - name: Databricks Production
    command: uvx
    args:
      - databricks-mcp
    env:
      DATABRICKS_HOST: https://prod-workspace.cloud.databricks.com
      DATABRICKS_CLIENT_ID: ${DATABRICKS_PROD_CLIENT_ID}
      DATABRICKS_CLIENT_SECRET: ${DATABRICKS_PROD_CLIENT_SECRET}

  - name: Databricks Development
    command: uvx
    args:
      - databricks-mcp
    env:
      DATABRICKS_HOST: https://dev-workspace.cloud.databricks.com
      DATABRICKS_AUTH_TYPE: oauth-u2m
```

#### 5.7 ì›ê²© MCP ì„œë²„ ì„¤ì •

ContinueëŠ” HTTP ê¸°ë°˜ ì›ê²© ì„œë²„ë„ ì§€ì›í•©ë‹ˆë‹¤:

```yaml
mcpServers:
  - name: Databricks Remote
    transport: streamable-http
    url: https://your-mcp-server.com/mcp
    headers:
      Authorization: Bearer ${MCP_TOKEN}
```

#### 5.8 ì„¤ì • í™•ì¸

1. VS Code ì¬ì‹œì‘
2. Continue íŒ¨ë„ ì—´ê¸°
3. ì„¤ì • ì•„ì´ì½˜ í´ë¦­
4. "MCP Servers" ì„¹ì…˜ í™•ì¸
5. "databricks" ì„œë²„ê°€ ì—°ê²°ë¨ìœ¼ë¡œ í‘œì‹œë˜ëŠ”ì§€ í™•ì¸

#### 5.9 í…ŒìŠ¤íŠ¸

Continue ì±„íŒ…ì—ì„œ:
```
@databricks list my clusters
@databricks show tables in main.default
```

---

### 6. Zed Editor

ZedëŠ” ê³ ì„±ëŠ¥ í˜‘ì—… ì½”ë“œ ì—ë””í„°ì…ë‹ˆë‹¤.

#### 6.1 ì„¤ì • íŒŒì¼ ì ‘ê·¼

**ë°©ë²• 1: Zed UI ì‚¬ìš©**
1. Zed ì—´ê¸°
2. `Cmd+,` (ì„¤ì • ì—´ê¸°)
3. "Preferences" > "Settings" í´ë¦­
4. JSON í¸ì§‘ê¸°ê°€ ì—´ë¦½ë‹ˆë‹¤

**ë°©ë²• 2: ì§ì ‘ íŒŒì¼ í¸ì§‘**
```bash
# macOS/Linux
~/.config/zed/settings.json

# ì—´ê¸°
code ~/.config/zed/settings.json
```

#### 6.2 MCP í™•ì¥ ì„¤ì¹˜ (ê°„í¸í•œ ë°©ë²•)

1. Zedì—ì„œ Agent íŒ¨ë„ ì—´ê¸°
2. ìš°ì¸¡ ìƒë‹¨ ë©”ë‰´ í´ë¦­
3. "View Server Extensions" ì„ íƒ
4. "databricks" ê²€ìƒ‰ (ì»¤ë®¤ë‹ˆí‹° í™•ì¥ ì‚¬ìš© ê°€ëŠ¥ ì‹œ)
5. "Install" í´ë¦­

#### 6.3 ìˆ˜ë™ ì„¤ì •

`settings.json`ì— ë‹¤ìŒì„ ì¶”ê°€:

```json
{
  "context_servers": {
    "databricks": {
      "settings": {},
      "command": {
        "path": "uvx",
        "args": ["databricks-mcp"],
        "env": {
          "DATABRICKS_HOST": "https://your-workspace.cloud.databricks.com",
          "DATABRICKS_AUTH_TYPE": "oauth-u2m"
        }
      }
    }
  }
}
```

#### 6.4 ì™„ì „í•œ ì„¤ì • ì˜ˆì œ

```json
{
  "context_servers": {
    "databricks-production": {
      "settings": {
        "description": "Production Databricks workspace"
      },
      "command": {
        "path": "uvx",
        "args": ["databricks-mcp"],
        "env": {
          "DATABRICKS_HOST": "https://prod.cloud.databricks.com",
          "DATABRICKS_TOKEN": "dapi_prod_token"
        }
      }
    },
    "databricks-development": {
      "settings": {
        "description": "Development Databricks workspace"
      },
      "command": {
        "path": "uvx",
        "args": ["databricks-mcp"],
        "env": {
          "DATABRICKS_HOST": "https://dev.cloud.databricks.com",
          "DATABRICKS_AUTH_TYPE": "oauth-u2m"
        }
      }
    }
  }
}
```

#### 6.5 ë„êµ¬ í™œì„±í™”

1. ì„¤ì • íŒŒì¼ ì €ì¥
2. Zed ì¬ì‹œì‘
3. Agent íŒ¨ë„ ì—´ê¸°
4. "Configure profiles" ì„ íƒ
5. "databricks" í”„ë¡œíŒŒì¼ ì„ íƒ
6. "Configure MCP Tools" í´ë¦­
7. ì‚¬ìš©í•  ë„êµ¬ ì„ íƒ

#### 6.6 ì„œë²„ ìƒíƒœ í™•ì¸

1. Agent íŒ¨ë„ ì„¤ì • ë³´ê¸° ì—´ê¸°
2. MCP ì„œë²„ ì´ë¦„ ì˜†ì˜ í‘œì‹œê¸° í™•ì¸:
   - ğŸŸ¢ ë…¹ìƒ‰ ì  = "Server is active" (ì •ìƒ ì‘ë™)
   - ğŸ”´ ë¹¨ê°„ ì  = "Server error" (ì˜¤ë¥˜ ë°œìƒ)
   - âšª íšŒìƒ‰ ì  = "Server inactive" (ë¹„í™œì„±)

#### 6.7 í˜„ì¬ ì œí•œì‚¬í•­ (2025)

âš ï¸ **Zedì˜ MCP ì§€ì› ì œí•œ:**
- ìµœì‹  MCP ìŠ¤í™ (2025-06-18)ì€ ì•„ì§ ì™„ì „íˆ ì§€ì›ë˜ì§€ ì•ŠìŒ
- HTTP ìŠ¤íŠ¸ë¦¬ë°ì€ ì§€ì›ë˜ì§€ ì•ŠìŒ (stdioë§Œ ì§€ì›)
- í”„ë¡¬í”„íŠ¸ë§Œ ì§€ì› (ìŠ¬ë˜ì‹œ ëª…ë ¹ìœ¼ë¡œ í‘œì‹œ)
- ì—¬ëŸ¬ í”„ë¡¬í”„íŠ¸ ì¸ìˆ˜ëŠ” ì§€ì›ë˜ì§€ ì•ŠìŒ

#### 6.8 í…ŒìŠ¤íŠ¸

Zed Agentì—ì„œ:
```
/databricks-prompt list-clusters
```

ë˜ëŠ” ìì—°ì–´:
```
Show me all my Databricks clusters
List tables in the main catalog
```

---

### 7. Windsurf IDE

WindsurfëŠ” Codeiumì´ ê°œë°œí•œ AI ê¸°ë°˜ IDEì…ë‹ˆë‹¤.

#### 7.1 ì„¤ì • íŒŒì¼ ìœ„ì¹˜

```
~/.codeium/windsurf/mcp_config.json
```

#### 7.2 UIë¥¼ í†µí•œ ì„¤ì •

**ë°©ë²• 1: ì„¤ì • ë©”ë‰´**
1. Windsurf ì—´ê¸°
2. Settings > Advanced Settings
3. "Cascade" ì„¹ì…˜ê¹Œì§€ ìŠ¤í¬ë¡¤
4. "Add New Server" í´ë¦­
5. ì„œë²„ ì •ë³´ ì…ë ¥

**ë°©ë²• 2: Command Palette**
1. `Cmd+Shift+P` (macOS) ë˜ëŠ” `Ctrl+Shift+P` (Windows/Linux)
2. "Open Windsurf Settings Page" ì…ë ¥
3. "Cascade" > "MCP Servers" ì„¹ì…˜ ì°¾ê¸°
4. "Add Custom Server +" í´ë¦­

**ë°©ë²• 3: Cascade íˆ´ë°”**
1. Windsurfì—ì„œ Cascade ì—´ê¸°
2. íˆ´ë°”ì˜ ğŸ”¨ (Hammer) ì•„ì´ì½˜ í´ë¦­
3. "Configure" ë²„íŠ¼ í´ë¦­

#### 7.3 ê¸°ë³¸ ì„¤ì •

```json
{
  "mcpServers": {
    "databricks": {
      "command": "uvx",
      "args": ["databricks-mcp"],
      "env": {
        "DATABRICKS_HOST": "https://your-workspace.cloud.databricks.com",
        "DATABRICKS_AUTH_TYPE": "oauth-u2m"
      },
      "disabled": false,
      "alwaysAllow": []
    }
  }
}
```

#### 7.4 ë¡œì»¬ ì„œë²„ ì„¤ì • (Node.js)

ë¹Œë“œëœ MCP ì„œë²„ë¥¼ ë¡œì»¬ì—ì„œ ì‹¤í–‰í•˜ëŠ” ê²½ìš°:

```json
{
  "mcpServers": {
    "databricks": {
      "command": "node",
      "args": ["/path/to/databricks-mcp/build/index.js"],
      "env": {
        "DATABRICKS_HOST": "https://your-workspace.cloud.databricks.com",
        "DATABRICKS_TOKEN": "dapi..."
      },
      "disabled": false
    }
  }
}
```

#### 7.5 Docker ê¸°ë°˜ ì„¤ì •

Dockerë¥¼ ì‚¬ìš©í•˜ëŠ” ê²½ìš°:

```json
{
  "mcpServers": {
    "databricks": {
      "command": "docker",
      "args": [
        "run",
        "-i",
        "--rm",
        "-e", "DATABRICKS_HOST",
        "-e", "DATABRICKS_TOKEN",
        "your-dockerhub-username/databricks-mcp"
      ],
      "env": {
        "DATABRICKS_HOST": "https://your-workspace.cloud.databricks.com",
        "DATABRICKS_TOKEN": "dapi..."
      }
    }
  }
}
```

#### 7.6 ì›ê²© MCP ì„œë²„ ì„¤ì •

ì›ê²© í˜¸ìŠ¤íŒ… MCP ì„œë²„ë¥¼ ì‚¬ìš©í•˜ëŠ” ê²½ìš°:

```json
{
  "mcpServers": {
    "databricks-remote": {
      "command": "npx",
      "args": [
        "mcp-remote",
        "https://your-mcp-server.com/sse"
      ],
      "env": {
        "MCP_TOKEN": "your-auth-token"
      }
    }
  }
}
```

#### 7.7 ì—¬ëŸ¬ í™˜ê²½ ì„¤ì •

```json
{
  "mcpServers": {
    "databricks-production": {
      "command": "uvx",
      "args": ["databricks-mcp"],
      "env": {
        "DATABRICKS_HOST": "https://prod.cloud.databricks.com",
        "DATABRICKS_CLIENT_ID": "prod-client-id",
        "DATABRICKS_CLIENT_SECRET": "prod-secret"
      },
      "disabled": false,
      "alwaysAllow": ["list_clusters", "list_jobs"]
    },
    "databricks-staging": {
      "command": "uvx",
      "args": ["databricks-mcp"],
      "env": {
        "DATABRICKS_HOST": "https://staging.cloud.databricks.com",
        "DATABRICKS_TOKEN": "dapi_staging..."
      },
      "disabled": false
    },
    "databricks-development": {
      "command": "uvx",
      "args": ["databricks-mcp"],
      "env": {
        "DATABRICKS_HOST": "https://dev.cloud.databricks.com",
        "DATABRICKS_AUTH_TYPE": "oauth-u2m"
      },
      "disabled": true
    }
  }
}
```

#### 7.8 ì‚¬ì „ êµ¬ì„±ëœ ì„œë²„ ì‚¬ìš©

WindsurfëŠ” ì¸ê¸°ìˆëŠ” MCP ì„œë²„ë“¤ì„ ì‚¬ì „ êµ¬ì„±í•˜ì—¬ ì œê³µí•©ë‹ˆë‹¤:

1. Windsurfì—ì„œ Plugins ì•„ì´ì½˜ í´ë¦­ (ì‚¬ì´ë“œë°”)
2. "MCP Servers" íƒ­ ì„ íƒ
3. ì‚¬ìš© ê°€ëŠ¥í•œ ì„œë²„ ëª©ë¡ í™•ì¸
4. "databricks-mcp" ì°¾ê¸° (ì‚¬ìš© ê°€ëŠ¥í•œ ê²½ìš°)
5. "Install" ë˜ëŠ” "Enable" í´ë¦­

#### 7.9 ì„¤ì • í™•ì¸

1. Windsurf ì¬ì‹œì‘
2. Cascade íŒ¨ë„ ì—´ê¸°
3. ğŸ”¨ ì•„ì´ì½˜ í´ë¦­í•˜ì—¬ MCP ë„êµ¬ ëª©ë¡ í™•ì¸
4. "databricks" ì„œë²„ê°€ ì—°ê²°ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
5. ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ ëª©ë¡ í™•ì¸

#### 7.10 í…ŒìŠ¤íŠ¸

Cascadeì—ì„œ:
```
@databricks list all my clusters
@databricks show me tables in the main catalog
@databricks execute SQL: SELECT * FROM samples.nyctaxi.trips LIMIT 5
```

---

### 8. OpenAI Codex (CLI)

OpenAI CodexëŠ” í„°ë¯¸ë„ì—ì„œ ì‹¤í–‰ë˜ëŠ” ê²½ëŸ‰ ì½”ë”© ì—ì´ì „íŠ¸ë¡œ, MCP ì„œë²„ë¥¼ ì™„ì „íˆ ì§€ì›í•©ë‹ˆë‹¤.

#### 8.1 Codex ì„¤ì¹˜

```bash
# npmì„ í†µí•œ ì„¤ì¹˜
npm install -g @openai/codex

# ë˜ëŠ” ì§ì ‘ ì‹¤í–‰
npx @openai/codex
```

#### 8.2 ì„¤ì • íŒŒì¼ ìœ„ì¹˜

```
~/.codex/config.toml
```

#### 8.3 MCP ì„œë²„ ì¶”ê°€

**ëª…ë ¹ì–´ë¥¼ í†µí•œ ì¶”ê°€:**
```bash
codex mcp add databricks \
  --env DATABRICKS_HOST=https://your-workspace.cloud.databricks.com \
  --env DATABRICKS_AUTH_TYPE=oauth-u2m \
  -- uvx databricks-mcp
```

**PAT ì‚¬ìš©:**
```bash
codex mcp add databricks \
  --env DATABRICKS_HOST=https://your-workspace.cloud.databricks.com \
  --env DATABRICKS_TOKEN=dapi... \
  -- uvx databricks-mcp
```

**Service Principal ì‚¬ìš©:**
```bash
codex mcp add databricks \
  --env DATABRICKS_HOST=https://your-workspace.cloud.databricks.com \
  --env DATABRICKS_CLIENT_ID=your-client-id \
  --env DATABRICKS_CLIENT_SECRET=your-secret \
  -- uvx databricks-mcp
```

#### 8.4 ìˆ˜ë™ ì„¤ì • (config.toml)

```bash
# ì„¤ì • íŒŒì¼ í¸ì§‘
nano ~/.codex/config.toml
```

**ê¸°ë³¸ ì„¤ì •:**
```toml
[[mcp_servers]]
name = "databricks"
command = "uvx"
args = ["databricks-mcp"]

[mcp_servers.env]
DATABRICKS_HOST = "https://your-workspace.cloud.databricks.com"
DATABRICKS_AUTH_TYPE = "oauth-u2m"
```

**ì—¬ëŸ¬ ì›Œí¬ìŠ¤í˜ì´ìŠ¤ ì„¤ì •:**
```toml
[[mcp_servers]]
name = "databricks-prod"
command = "uvx"
args = ["databricks-mcp"]

[mcp_servers.env]
DATABRICKS_HOST = "https://prod-workspace.cloud.databricks.com"
DATABRICKS_TOKEN = "dapi_prod..."

[[mcp_servers]]
name = "databricks-dev"
command = "uvx"
args = ["databricks-mcp"]

[mcp_servers.env]
DATABRICKS_HOST = "https://dev-workspace.cloud.databricks.com"
DATABRICKS_AUTH_TYPE = "oauth-u2m"
```

#### 8.5 MCP ì„œë²„ ëª©ë¡ í™•ì¸

```bash
# Codex TUIì—ì„œ
codex

# TUI ë‚´ì—ì„œ
/mcp
```

í™œì„± ì—°ê²°ëœ MCP ì„œë²„ ëª©ë¡ì´ í‘œì‹œë©ë‹ˆë‹¤.

#### 8.6 MCP ì„œë²„ ê´€ë¦¬

**ì„œë²„ ì œê±°:**
```bash
codex mcp remove databricks
```

**ì„œë²„ ëª©ë¡:**
```bash
codex mcp list
```

#### 8.7 Codexë¥¼ MCP ì„œë²„ë¡œ ì‚¬ìš©

Codex ìì²´ë¥¼ MCP ì„œë²„ë¡œ ì‹¤í–‰í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤:

```bash
# MCP ì„œë²„ë¡œ Codex ì‹œì‘
codex mcp-server

# MCP Inspectorë¡œ í…ŒìŠ¤íŠ¸
npx @modelcontextprotocol/inspector codex mcp-server
```

#### 8.8 Docker MCP Toolkit ì‚¬ìš©

Docker MCP Toolkitì„ í†µí•´ 220ê°œ ì´ìƒì˜ MCP ì„œë²„ì— ì•ˆì „í•˜ê²Œ ì ‘ê·¼í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

```bash
# Docker MCP Toolkit ì„¤ì¹˜
npm install -g @docker/mcp-toolkit

# Databricks MCP ì„œë²„ ì¶”ê°€
docker-mcp add databricks
```

#### 8.9 í…ŒìŠ¤íŠ¸

Codex TUIì—ì„œ:
```bash
# Codex ì‹œì‘
codex

# í”„ë¡¬í”„íŠ¸ì—ì„œ
> List all my Databricks clusters
> Show tables in catalog 'main'
> Execute SQL: SELECT * FROM samples.nyctaxi.trips LIMIT 5
```

#### 8.10 OpenAI Agents SDKì™€ í†µí•©

Codexë¥¼ OpenAI Agents SDKì™€ í•¨ê»˜ ì‚¬ìš©:

```python
from openai import OpenAI
from codex_mcp import CodexMCPServer

# MCP ì„œë²„ë¡œ Codex ì´ˆê¸°í™”
server = CodexMCPServer()

# Agentì—ì„œ ì‚¬ìš©
client = OpenAI()
response = client.chat.completions.create(
    model="gpt-4",
    messages=[
        {"role": "user", "content": "List my Databricks clusters"}
    ],
    tools=server.get_tools()
)
```

---

### 9. Dify

DifyëŠ” v1.6.0ë¶€í„° ì–‘ë°©í–¥ MCP ì§€ì›ì„ ì œê³µí•˜ëŠ” LLMOps í”Œë«í¼ì…ë‹ˆë‹¤.

#### 9.1 Difyì—ì„œ MCP ì„œë²„ ì‚¬ìš©

DifyëŠ” ë‘ ê°€ì§€ ë°©ì‹ìœ¼ë¡œ MCPë¥¼ ì§€ì›í•©ë‹ˆë‹¤:
1. **MCP ë„êµ¬ë¥¼ Difyë¡œ ê°€ì ¸ì˜¤ê¸°** (MCP ì„œë²„ ì†Œë¹„)
2. **Dify ì•±ì„ MCP ì„œë²„ë¡œ ê²Œì‹œ** (MCP ì„œë²„ ì œê³µ)

#### 9.2 MCP ì„œë²„ ì¶”ê°€ (Difyì—ì„œ ì‚¬ìš©)

**ë°©ë²• 1: Dify UIë¥¼ í†µí•œ ì¶”ê°€**

1. Dify ì›Œí¬ìŠ¤í˜ì´ìŠ¤ì— ë¡œê·¸ì¸
2. **Tools** (ë„êµ¬) í˜ì´ì§€ë¡œ ì´ë™
3. **MCP** ì„¹ì…˜ ì„ íƒ
4. **Add Server** (ì„œë²„ ì¶”ê°€) í´ë¦­
5. ì„œë²„ ì •ë³´ ì…ë ¥:

```json
{
  "name": "databricks",
  "type": "stdio",
  "command": "uvx",
  "args": ["databricks-mcp"],
  "env": {
    "DATABRICKS_HOST": "https://your-workspace.cloud.databricks.com",
    "DATABRICKS_AUTH_TYPE": "oauth-u2m"
  }
}
```

**ë°©ë²• 2: í™˜ê²½ ë³€ìˆ˜ ì‚¬ìš©**

Dify ì„œë²„ í™˜ê²½ì—ì„œ ì§ì ‘ ì„¤ì •:

```bash
export DIFY_MCP_SERVERS='[
  {
    "name": "databricks",
    "command": "uvx",
    "args": ["databricks-mcp"],
    "env": {
      "DATABRICKS_HOST": "https://your-workspace.cloud.databricks.com",
      "DATABRICKS_TOKEN": "dapi..."
    }
  }
]'
```

#### 9.3 Agent ì›Œí¬í”Œë¡œìš°ì—ì„œ ì‚¬ìš©

**1. Agent ë…¸ë“œ ìƒì„±:**
- Workflowì—ì„œ **Agent** ë…¸ë“œ ì¶”ê°€
- MCP Tools ì„¹ì…˜ì—ì„œ **databricks** ì„ íƒ
- ì‚¬ìš©í•  ë„êµ¬ ì„ íƒ:
  - `list_clusters`
  - `execute_sql`
  - `list_tables`
  - ë“±

**2. Agentê°€ ìë™ìœ¼ë¡œ ë„êµ¬ í˜¸ì¶œ:**
```
User: "Show me all running clusters"
â†’ Agentê°€ list_clusters ë„êµ¬ë¥¼ ìë™ í˜¸ì¶œ
â†’ ê²°ê³¼ ë°˜í™˜
```

#### 9.4 ì›Œí¬í”Œë¡œìš° ë…¸ë“œë¡œ ì‚¬ìš©

**ê°œë³„ MCP ë„êµ¬ë¥¼ ë…¸ë“œë¡œ ì¶”ê°€:**

1. Workflow í¸ì§‘ê¸° ì—´ê¸°
2. **Add Node** í´ë¦­
3. **MCP Tool** ì¹´í…Œê³ ë¦¬ ì„ íƒ
4. **databricks** > **execute_sql** ì„ íƒ
5. íŒŒë¼ë¯¸í„° ì„¤ì •:
   ```json
   {
     "warehouse_id": "{{warehouse_id}}",
     "sql": "SELECT * FROM main.default.my_table"
   }
   ```

ì´ ë°©ì‹ì€ LLM ê²°ì • ì—†ì´ ëª…ì‹œì ì¸ í˜¸ì¶œ ìˆœì„œë¥¼ ì œì–´í•©ë‹ˆë‹¤.

#### 9.5 Dify ì•±ì„ MCP ì„œë²„ë¡œ ê²Œì‹œ

Dify ì›Œí¬í”Œë¡œìš°ë¥¼ MCP ì„œë²„ë¡œ ë…¸ì¶œí•˜ì—¬ Claude, Cursor ë“±ì—ì„œ ì‚¬ìš©:

**1. ì›Œí¬í”Œë¡œìš° ì¤€ë¹„:**

Start ë…¸ë“œì˜ ëª¨ë“  ì…ë ¥ íŒŒë¼ë¯¸í„°ì— ëŒ€í•´:
- **íŒŒë¼ë¯¸í„° ì´ë¦„**: ëª…í™•í•œ ì´ë¦„ (ì˜ˆ: `cluster_name`, `sql_query`)
- **íŒŒë¼ë¯¸í„° ì„¤ëª…**: ìƒì„¸í•œ ì„¤ëª… ì‘ì„±
  ```
  ì˜ˆ: "The name of the Databricks cluster to query"
  ```

**2. ì„œë¹„ìŠ¤ ì„¤ëª… ì‘ì„±:**

ì›Œí¬í”Œë¡œìš° ì„¤ì •ì—ì„œ:
```
Service Description: "Query Databricks clusters and execute SQL through a Dify workflow"
```

**3. MCP ì„œë²„ URL ìƒì„±:**

- ì„¤ì • ì™„ë£Œ í›„ Difyê°€ MCP ì„œë²„ URL ë°œê¸‰
- ì˜ˆ: `https://your-dify.com/mcp/v1/workflows/abc123`

**4. Claude Desktopì—ì„œ ì‚¬ìš©:**

```json
{
  "mcpServers": {
    "dify-databricks": {
      "url": "https://your-dify.com/mcp/v1/workflows/abc123",
      "headers": {
        "Authorization": "Bearer YOUR_DIFY_API_KEY"
      }
    }
  }
}
```

**5. Cursorì—ì„œ ì‚¬ìš©:**

`.cursor/mcp.json`:
```json
{
  "mcpServers": {
    "dify-databricks": {
      "url": "https://your-dify.com/mcp/v1/workflows/abc123",
      "headers": {
        "Authorization": "Bearer YOUR_DIFY_API_KEY"
      }
    }
  }
}
```

#### 9.6 Zapier/Composio í†µí•©

Dify MCPëŠ” Zapierì™€ Composioë¥¼ í†µí•´ 8,000ê°œ ì´ìƒì˜ ì•±ì— ì ‘ê·¼í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

**Zapier MCP ì¶”ê°€:**
1. Tools í˜ì´ì§€ì—ì„œ **MCP** ì„ íƒ
2. **Zapier** ì„œë²„ ì¶”ê°€
3. Zapier API í‚¤ ì…ë ¥
4. ì‚¬ìš©í•  Zapier Actions ì„ íƒ

**ì‚¬ìš© ì˜ˆ:**
```
"Databricksì—ì„œ ë°ì´í„°ë¥¼ ì¿¼ë¦¬í•˜ê³  ê²°ê³¼ë¥¼ Google Sheetsì— ì €ì¥"
â†’ Databricks MCPë¡œ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
â†’ Zapier MCPë¡œ Google Sheetsì— ì“°ê¸°
```

#### 9.7 ì»¤ë®¤ë‹ˆí‹° MCP ì„œë²„ (dify-mcp-server)

ì„œë“œíŒŒí‹° MCP ì„œë²„ë¥¼ ì‚¬ìš©í•˜ì—¬ Dify ì›Œí¬í”Œë¡œìš° í˜¸ì¶œ:

**ì„¤ì¹˜:**
```bash
npm install -g dify-mcp-server
```

**ì„¤ì •:**
```yaml
# config.yaml
dify:
  base_url: https://your-dify.com
  app_sks:
    - app-abc123-secret-key-1
    - app-def456-secret-key-2
```

**ì‹¤í–‰:**
```bash
dify-mcp-server --config config.yaml
```

**Claude Desktop ì„¤ì •:**
```json
{
  "mcpServers": {
    "dify": {
      "command": "dify-mcp-server",
      "args": ["--config", "/path/to/config.yaml"]
    }
  }
}
```

#### 9.8 ì„¤ì • í™•ì¸

**MCP ì„œë²„ ìƒíƒœ í™•ì¸:**
1. Dify Tools í˜ì´ì§€ ì—´ê¸°
2. MCP ì„¹ì…˜ì—ì„œ ì—°ê²° ìƒíƒœ í™•ì¸
3. ë…¹ìƒ‰ í‘œì‹œ = ì •ìƒ ì—°ê²°

**ë„êµ¬ í…ŒìŠ¤íŠ¸:**
1. Workflowì—ì„œ Agent ë…¸ë“œ ìƒì„±
2. "List my Databricks clusters" ìš”ì²­
3. Agentê°€ MCP ë„êµ¬ë¥¼ í˜¸ì¶œí•˜ëŠ”ì§€ í™•ì¸

#### 9.9 ê³ ê¸‰ ì„¤ì •

**ì—¬ëŸ¬ Databricks ì›Œí¬ìŠ¤í˜ì´ìŠ¤:**

```json
[
  {
    "name": "databricks-prod",
    "command": "uvx",
    "args": ["databricks-mcp"],
    "env": {
      "DATABRICKS_HOST": "https://prod.cloud.databricks.com",
      "DATABRICKS_TOKEN": "dapi_prod..."
    }
  },
  {
    "name": "databricks-dev",
    "command": "uvx",
    "args": ["databricks-mcp"],
    "env": {
      "DATABRICKS_HOST": "https://dev.cloud.databricks.com",
      "DATABRICKS_AUTH_TYPE": "oauth-u2m"
    }
  }
]
```

**ê¶Œí•œ ì„¤ì •:**
- Dify Admin ê¶Œí•œìœ¼ë¡œ MCP ì„œë²„ ì¶”ê°€
- íŒ€ ë©¤ë²„ì—ê²Œ ë„êµ¬ ì‚¬ìš© ê¶Œí•œ ë¶€ì—¬
- API í‚¤ ë³„ë„ ê´€ë¦¬

#### 9.10 í…ŒìŠ¤íŠ¸

**Agent ì›Œí¬í”Œë¡œìš°ì—ì„œ:**
```
User: "What clusters are running in my Databricks workspace?"
â†’ Dify Agentê°€ databricks MCP ì„œë²„ í˜¸ì¶œ
â†’ list_clusters ë„êµ¬ ì‚¬ìš©
â†’ ê²°ê³¼ë¥¼ ìì—°ì–´ë¡œ í¬ë§·íŒ…í•˜ì—¬ ë°˜í™˜
```

**ì›Œí¬í”Œë¡œìš° ë…¸ë“œë¡œ:**
```
[Start] â†’ [MCP: list_clusters] â†’ [LLM: ê²°ê³¼ ë¶„ì„] â†’ [End]
```

---

### 10. n8n

n8nì€ ì›Œí¬í”Œë¡œìš° ìë™í™” í”Œë«í¼ìœ¼ë¡œ, MCPë¥¼ í´ë¼ì´ì–¸íŠ¸ì™€ ì„œë²„ ì–‘ë°©í–¥ìœ¼ë¡œ ì§€ì›í•©ë‹ˆë‹¤.

#### 10.1 n8n MCP ì§€ì› ê°œìš”

n8nì€ ë‘ ê°€ì§€ ë°©ì‹ìœ¼ë¡œ MCPë¥¼ ì§€ì›í•©ë‹ˆë‹¤:
1. **MCP í´ë¼ì´ì–¸íŠ¸**: n8nì—ì„œ ì™¸ë¶€ MCP ì„œë²„ ë„êµ¬ í˜¸ì¶œ
2. **MCP ì„œë²„**: n8n ì›Œí¬í”Œë¡œìš°ë¥¼ MCP ì„œë²„ë¡œ ë…¸ì¶œ

#### 10.2 n8n ì„¤ì¹˜

```bash
# npmì„ í†µí•œ ì „ì—­ ì„¤ì¹˜
npm install -g n8n

# Docker ì‚¬ìš©
docker run -it --rm --name n8n -p 5678:5678 n8nio/n8n

# npxë¡œ ì§ì ‘ ì‹¤í–‰
npx n8n
```

#### 10.3 MCP Client Tool ë…¸ë“œ ì‚¬ìš©

n8nì—ì„œ Databricks MCP ì„œë²„ í˜¸ì¶œ:

**1. ì›Œí¬í”Œë¡œìš° ìƒì„±:**
1. n8n ëŒ€ì‹œë³´ë“œì—ì„œ "New Workflow" í´ë¦­
2. ë…¸ë“œ ì¶”ê°€ â†’ "AI" ì¹´í…Œê³ ë¦¬
3. "MCP Client Tool" ë…¸ë“œ ì„ íƒ

**2. MCP ì„œë²„ ì—°ê²° ì„¤ì •:**

ë…¸ë“œ ì„¤ì •ì—ì„œ:
```json
{
  "transport": "stdio",
  "command": "uvx",
  "args": ["databricks-mcp"],
  "env": {
    "DATABRICKS_HOST": "https://your-workspace.cloud.databricks.com",
    "DATABRICKS_AUTH_TYPE": "oauth-u2m"
  }
}
```

**3. HTTP Streamable ì „ì†¡ ë°©ì‹:**

ì›ê²© MCP ì„œë²„ë¥¼ ì‚¬ìš©í•˜ëŠ” ê²½ìš°:
```json
{
  "transport": "http-streamable",
  "url": "https://your-mcp-server.com/mcp",
  "headers": {
    "Authorization": "Bearer YOUR_TOKEN"
  }
}
```

#### 10.4 Agentì—ì„œ MCP ë„êµ¬ ì‚¬ìš©

**AI Agent ë…¸ë“œ ì„¤ì •:**

1. **Agent ë…¸ë“œ ì¶”ê°€**:
   - "AI" â†’ "AI Agent" ë…¸ë“œ ì¶”ê°€
   - Model ì„ íƒ (OpenAI, Anthropic ë“±)

2. **MCP Tools ì—°ê²°**:
   - Tools ì„¹ì…˜ì—ì„œ "MCP Client Tool" ì¶”ê°€
   - Databricks MCP ì„œë²„ ì„¤ì •

3. **í”„ë¡¬í”„íŠ¸ ì˜ˆì œ**:
```
Input: "List all running Databricks clusters and their current state"
â†’ Agentê°€ ìë™ìœ¼ë¡œ list_clusters MCP ë„êµ¬ í˜¸ì¶œ
â†’ ê²°ê³¼ ë¶„ì„ ë° ì‘ë‹µ
```

#### 10.5 n8nì„ MCP ì„œë²„ë¡œ ë…¸ì¶œ

n8n ì›Œí¬í”Œë¡œìš°ë¥¼ MCP ì„œë²„ë¡œ ë§Œë“¤ì–´ Claude, Cursor ë“±ì—ì„œ ì‚¬ìš©:

**1. MCP Server Trigger ë…¸ë“œ ì‚¬ìš©:**

1. ìƒˆ ì›Œí¬í”Œë¡œìš° ìƒì„±
2. "MCP Server Trigger" ë…¸ë“œ ì¶”ê°€
3. ë„êµ¬ ì´ë¦„ ë° ì„¤ëª… ì…ë ¥:
   ```
   Tool Name: query_databricks
   Description: Execute SQL queries on Databricks and format results
   ```

4. íŒŒë¼ë¯¸í„° ì •ì˜:
   ```json
   {
     "sql": {
       "type": "string",
       "description": "SQL query to execute",
       "required": true
     },
     "warehouse_id": {
       "type": "string",
       "description": "SQL Warehouse ID"
     }
   }
   ```

5. ì›Œí¬í”Œë¡œìš° ë¡œì§ êµ¬ì„±:
   - HTTP Request ë…¸ë“œë¡œ Databricks API í˜¸ì¶œ
   - ê²°ê³¼ ì²˜ë¦¬ ë° í¬ë§·íŒ…
   - Return ë…¸ë“œë¡œ ê²°ê³¼ ë°˜í™˜

**2. n8n MCP ì„œë²„ URL:**

ì›Œí¬í”Œë¡œìš° í™œì„±í™” í›„ MCP ì„œë²„ URL í™•ì¸:
```
http://localhost:5678/mcp/workflows/<workflow-id>
```

**3. Claude Desktopì—ì„œ n8n MCP ì„œë²„ ì‚¬ìš©:**

```json
{
  "mcpServers": {
    "n8n-databricks": {
      "url": "http://localhost:5678/mcp/workflows/<workflow-id>",
      "headers": {
        "Authorization": "Bearer YOUR_N8N_API_KEY"
      }
    }
  }
}
```

#### 10.6 ì»¤ë®¤ë‹ˆí‹° ë…¸ë“œ ì‚¬ìš©

**n8n-nodes-mcp ì„¤ì¹˜:**

```bash
# n8n Community Nodesì—ì„œ ì„¤ì¹˜
cd ~/.n8n
npm install n8n-nodes-mcp
```

ì´ ì»¤ìŠ¤í…€ ë…¸ë“œëŠ” ë‹¤ìŒì„ ì§€ì›í•©ë‹ˆë‹¤:
- âœ… HTTP Streamable transport
- âœ… SSE (Server-Sent Events)
- âœ… Command-line transport
- âœ… Bearer & generic header ì¸ì¦

#### 10.7 ì‹¤ì „ ì˜ˆì œ: Databricks ìë™í™”

**ìë™í™” ì‹œë‚˜ë¦¬ì˜¤: ë§¤ì¼ í´ëŸ¬ìŠ¤í„° ìƒíƒœ ëª¨ë‹ˆí„°ë§**

```
[Schedule Trigger: Daily 9 AM]
  â†“
[MCP Client Tool: list_clusters]
  â†“
[Code: Filter running clusters]
  â†“
[IF: Any cluster issues?]
  â†“ Yes
[Slack: Send alert]
  â†“ No
[Email: Daily report]
```

**ì›Œí¬í”Œë¡œìš° ì„¤ì •:**

1. **Schedule Trigger** - ë§¤ì¼ ì˜¤ì „ 9ì‹œ
2. **MCP Client Tool** - Databricks MCP ì„œë²„ í˜¸ì¶œ
3. **Code ë…¸ë“œ** - í´ëŸ¬ìŠ¤í„° ìƒíƒœ ë¶„ì„
4. **IF ë…¸ë“œ** - ë¬¸ì œ ê°ì§€
5. **Slack/Email** - ì•Œë¦¼ ì „ì†¡

#### 10.8 í™˜ê²½ ë³€ìˆ˜ ì„¤ì •

n8nì—ì„œ í™˜ê²½ ë³€ìˆ˜ ì‚¬ìš©:

**n8n ì„œë²„ ì‹œì‘ ì‹œ:**
```bash
export N8N_MCP_DATABRICKS_HOST="https://your-workspace.cloud.databricks.com"
export N8N_MCP_DATABRICKS_TOKEN="dapi..."

n8n start
```

**Docker Compose:**
```yaml
version: '3.8'
services:
  n8n:
    image: n8nio/n8n
    ports:
      - "5678:5678"
    environment:
      - N8N_MCP_DATABRICKS_HOST=https://your-workspace.cloud.databricks.com
      - N8N_MCP_DATABRICKS_TOKEN=dapi...
    volumes:
      - n8n_data:/home/node/.n8n
```

#### 10.9 Account API ì„¤ì •

Account-level ì‘ì—…ì„ ìœ„í•œ ì„¤ì •:

```json
{
  "transport": "stdio",
  "command": "uvx",
  "args": ["databricks-mcp"],
  "env": {
    "DATABRICKS_HOST": "https://your-workspace.cloud.databricks.com",
    "DATABRICKS_AUTH_TYPE": "oauth-u2m",
    "DATABRICKS_ACCOUNT_ID": "your-account-id",
    "DATABRICKS_ACCOUNT_HOST": "https://accounts.cloud.databricks.com"
  }
}
```

#### 10.10 í…ŒìŠ¤íŠ¸

**ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ ì›Œí¬í”Œë¡œìš°:**

1. Manual Trigger ë…¸ë“œ ì¶”ê°€
2. MCP Client Tool ë…¸ë“œ ì¶”ê°€ (Databricks ì„¤ì •)
3. Tool: `list_clusters`
4. Parameters: `{}`
5. Workflow ì‹¤í–‰ â†’ í´ëŸ¬ìŠ¤í„° ëª©ë¡ í™•ì¸

---

### ë¬¸ì œ í•´ê²° (Korean)

#### ì¼ë°˜ì ì¸ ë¬¸ì œ

##### 1. "uvx: command not found" ì˜¤ë¥˜

**í•´ê²° ë°©ë²•:**
```bash
# uv ì„¤ì¹˜
# macOS/Linux
curl -LsSf https://astral.sh/uv/install.sh | sh

# Windows
powershell -c "irm https://astral.sh/uv/install.ps1 | iex"

# ì„¤ì¹˜ í™•ì¸
uvx --version
```

**ëŒ€ì•ˆ: pip ì‚¬ìš©**
```json
{
  "mcpServers": {
    "databricks": {
      "command": "python",
      "args": ["-m", "databricks_mcp"],
      "env": { ... }
    }
  }
}
```

##### 2. "Could not connect to Databricks" ì˜¤ë¥˜

**í™•ì¸ ì‚¬í•­:**
1. DATABRICKS_HOSTê°€ ì •í™•í•œì§€ í™•ì¸ (ëì— ìŠ¬ë˜ì‹œ ì—†ìŒ)
2. ë„¤íŠ¸ì›Œí¬ ì—°ê²° í™•ì¸
3. ì›Œí¬ìŠ¤í˜ì´ìŠ¤ URLì´ ì˜¬ë°”ë¥¸ì§€ í™•ì¸

```json
// âŒ ì˜ëª»ëœ ì˜ˆ
"DATABRICKS_HOST": "https://your-workspace.cloud.databricks.com/"

// âœ… ì˜¬ë°”ë¥¸ ì˜ˆ
"DATABRICKS_HOST": "https://your-workspace.cloud.databricks.com"
```

##### 3. "Authentication failed" ì˜¤ë¥˜

**OAuth ì‚¬ìš© ì‹œ:**
- ë¸Œë¼ìš°ì €ê°€ ìë™ìœ¼ë¡œ ì—´ë¦¬ëŠ”ì§€ í™•ì¸
- íŒì—… ì°¨ë‹¨ê¸° ë¹„í™œì„±í™”
- ì˜¬ë°”ë¥¸ ê³„ì •ìœ¼ë¡œ ë¡œê·¸ì¸í–ˆëŠ”ì§€ í™•ì¸

**PAT ì‚¬ìš© ì‹œ:**
- í† í°ì´ ë§Œë£Œë˜ì§€ ì•Šì•˜ëŠ”ì§€ í™•ì¸
- í† í°ì´ ì˜¬ë°”ë¥´ê²Œ ë³µì‚¬ë˜ì—ˆëŠ”ì§€ í™•ì¸ (ê³µë°± ì—†ì´)
- í† í°ì´ í•„ìš”í•œ ê¶Œí•œì„ ê°€ì§€ê³  ìˆëŠ”ì§€ í™•ì¸

**Service Principal ì‚¬ìš© ì‹œ:**
- Client IDì™€ Secretì´ ì •í™•í•œì§€ í™•ì¸
- Service Principalì´ ì›Œí¬ìŠ¤í˜ì´ìŠ¤ì— ì¶”ê°€ë˜ì—ˆëŠ”ì§€ í™•ì¸
- í•„ìš”í•œ ê¶Œí•œì´ ë¶€ì—¬ë˜ì—ˆëŠ”ì§€ í™•ì¸

##### 4. MCP ì„œë²„ ì•„ì´ì½˜ì´ ë³´ì´ì§€ ì•ŠìŒ

**í•´ê²° ë°©ë²•:**
1. í´ë¼ì´ì–¸íŠ¸ ì• í”Œë¦¬ì¼€ì´ì…˜ ì™„ì „íˆ ì¢…ë£Œ
2. ì„¤ì • íŒŒì¼ JSON êµ¬ë¬¸ í™•ì¸ (ì‰¼í‘œ, ê´„í˜¸ ë“±)
3. í´ë¼ì´ì–¸íŠ¸ ì¬ì‹œì‘
4. ë¡œê·¸ í™•ì¸ (í´ë¼ì´ì–¸íŠ¸ë³„ ë¡œê·¸ ìœ„ì¹˜ ì°¸ì¡°)

##### 5. ì¼ë¶€ ë„êµ¬ë§Œ ì‘ë™í•¨

**ì›ì¸:**
- ê¶Œí•œ ë¶€ì¡±
- í•„ìš”í•œ Databricks ê¸°ëŠ¥ì´ í™œì„±í™”ë˜ì§€ ì•ŠìŒ
- ì›Œí¬ìŠ¤í˜ì´ìŠ¤ í‹°ì–´ ì œí•œ

**í•´ê²° ë°©ë²•:**
1. Databricksì—ì„œ ì‚¬ìš©ì ê¶Œí•œ í™•ì¸
2. Unity Catalog, MLflow ë“± í•„ìš”í•œ ê¸°ëŠ¥ í™œì„±í™” í™•ì¸
3. ì›Œí¬ìŠ¤í˜ì´ìŠ¤ ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜

##### 6. ì„±ëŠ¥ì´ ëŠë¦¼

**ìµœì í™” ë°©ë²•:**
- ì‚¬ìš©í•˜ì§€ ì•ŠëŠ” MCP ì„œë²„ ë¹„í™œì„±í™”
- alwaysAllow ë¦¬ìŠ¤íŠ¸ ì‚¬ìš©í•˜ì—¬ ìì£¼ ì“°ëŠ” ë„êµ¬ ìë™ ìŠ¹ì¸
- ë¡œì»¬ì— í† í° ìºì‹œ (OAuth)

#### í´ë¼ì´ì–¸íŠ¸ë³„ ë¬¸ì œ

##### Claude Desktop

**ë¬¸ì œ:** ì„œë²„ê°€ ì—°ê²°ë˜ì§€ ì•ŠìŒ
```bash
# ë¡œê·¸ í™•ì¸
# macOS
tail -f ~/Library/Logs/Claude/mcp*.log

# Windows
type %APPDATA%\Claude\logs\mcp*.log
```

##### Cursor

**ë¬¸ì œ:** 40ê°œ ë„êµ¬ ì œí•œ
- í•„ìš”í•œ ê¸°ëŠ¥ë§Œ í¬í•¨í•˜ëŠ” ì»¤ìŠ¤í…€ ë˜í¼ ì‘ì„± ê³ ë ¤
- ì—¬ëŸ¬ MCP ì„œë²„ ì¸ìŠ¤í„´ìŠ¤ë¡œ ê¸°ëŠ¥ ë¶„í• 

##### Cline / Continue

**ë¬¸ì œ:** ë„êµ¬ ìŠ¹ì¸ í”„ë¡¬í”„íŠ¸ê°€ ê³„ì† ë‚˜íƒ€ë‚¨
- `alwaysAllow` ë¦¬ìŠ¤íŠ¸ì— ìì£¼ ì‚¬ìš©í•˜ëŠ” ë„êµ¬ ì¶”ê°€

##### Zed

**ë¬¸ì œ:** í”„ë¡¬í”„íŠ¸ë§Œ í‘œì‹œë¨
- Zedì˜ í˜„ì¬ MCP ì§€ì›ì€ ì œí•œì 
- ì§ì ‘ ë„êµ¬ í˜¸ì¶œì€ í–¥í›„ ì—…ë°ì´íŠ¸ ì˜ˆì •

##### Windsurf

**ë¬¸ì œ:** Docker ì»¨í…Œì´ë„ˆê°€ ì‹œì‘ë˜ì§€ ì•ŠìŒ
- Docker Desktop ì‹¤í–‰ í™•ì¸
- ì´ë¯¸ì§€ê°€ ì˜¬ë°”ë¥´ê²Œ ë¹Œë“œë˜ì—ˆëŠ”ì§€ í™•ì¸
- ë¡œê·¸ í™•ì¸: `docker logs <container-id>`

#### ë””ë²„ê¹… íŒ

##### 1. ìƒì„¸ ë¡œê¹… í™œì„±í™”

í™˜ê²½ ë³€ìˆ˜ ì¶”ê°€:
```json
{
  "env": {
    "DATABRICKS_HOST": "...",
    "DATABRICKS_DEBUG": "true",
    "DATABRICKS_LOG_LEVEL": "DEBUG"
  }
}
```

##### 2. ìˆ˜ë™ìœ¼ë¡œ MCP ì„œë²„ í…ŒìŠ¤íŠ¸

```bash
# ì„œë²„ ì§ì ‘ ì‹¤í–‰
uvx databricks-mcp

# í™˜ê²½ ë³€ìˆ˜ ì„¤ì •í•˜ì—¬ ì‹¤í–‰
DATABRICKS_HOST=https://your-workspace.cloud.databricks.com \
DATABRICKS_AUTH_TYPE=oauth-u2m \
uvx databricks-mcp
```

##### 3. Databricks CLIë¡œ ì—°ê²° í…ŒìŠ¤íŠ¸

```bash
# Databricks CLI ì„¤ì¹˜
pip install databricks-cli

# ì—°ê²° í…ŒìŠ¤íŠ¸
databricks workspace list
```

##### 4. ë„¤íŠ¸ì›Œí¬ í…ŒìŠ¤íŠ¸

```bash
# ì›Œí¬ìŠ¤í˜ì´ìŠ¤ ë„ë‹¬ ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
curl -I https://your-workspace.cloud.databricks.com

# API ì—”ë“œí¬ì¸íŠ¸ í…ŒìŠ¤íŠ¸
curl -H "Authorization: Bearer dapi..." \
  https://your-workspace.cloud.databricks.com/api/2.0/clusters/list
```

#### ë„ì›€ ë°›ê¸°

ë¬¸ì œê°€ ê³„ì†ë˜ë©´:

1. **GitHub Issues**: https://github.com/YuujinHwang/databricks-mcp/issues
2. **MCP ê³µì‹ ë¬¸ì„œ**: https://modelcontextprotocol.io/
3. **Databricks ë¬¸ì„œ**: https://docs.databricks.com/
4. **ì»¤ë®¤ë‹ˆí‹° í¬ëŸ¼**:
   - Databricks Community
   - MCP Discord
   - Stack Overflow (#mcp, #databricks)

ì´ìŠˆ ì œì¶œ ì‹œ í¬í•¨í•  ì •ë³´:
- ì‚¬ìš© ì¤‘ì¸ MCP í´ë¼ì´ì–¸íŠ¸ ë° ë²„ì „
- ìš´ì˜ ì²´ì œ ë° ë²„ì „
- ì„¤ì • íŒŒì¼ (ë¯¼ê°í•œ ì •ë³´ ì œê±°)
- ì˜¤ë¥˜ ë©”ì‹œì§€
- ë¡œê·¸ ì¶œë ¥

---

## English Guide

This guide provides detailed setup instructions for the Databricks MCP Server across all major MCP clients.

### Table of Contents
- [Prerequisites](#prerequisites)
- [1. Claude Desktop](#1-claude-desktop-en)
- [2. Claude Code (CLI)](#2-claude-code-cli-en)
- [3. Cursor IDE](#3-cursor-ide-en)
- [4. Cline (VS Code Extension)](#4-cline-vs-code-extension)
- [5. Continue (VS Code Extension)](#5-continue-vs-code-extension)
- [6. Zed Editor](#6-zed-editor-en)
- [7. Windsurf IDE](#7-windsurf-ide-en)
- [8. OpenAI Codex (CLI)](#8-openai-codex-cli-en)
- [9. Dify](#9-dify-en)
- [10. n8n](#10-n8n-en)
- [Troubleshooting](#troubleshooting-english)

---

### Prerequisites

Before configuring any MCP client, ensure you have:

#### 1. Python Environment (Recommended)
```bash
# Check Python 3.10+
python --version

# Install uv (recommended)
# macOS/Linux
curl -LsSf https://astral.sh/uv/install.sh | sh

# Windows (PowerShell)
powershell -c "irm https://astral.sh/uv/install.ps1 | iex"
```

#### 2. Databricks Authentication
Prepare one of the following:

**Option A: OAuth U2M (Recommended for development)**
- Databricks workspace URL
- OAuth auto-authentication (browser opens on first use)

**Option B: Personal Access Token (PAT)**
1. Log into Databricks workspace
2. Click user menu (top-right) â†’ Settings
3. Developer â†’ Access tokens
4. Click "Generate new token"
5. Copy and securely store the token

**Option C: Service Principal (For production)**
- Client ID
- Client Secret
- Request creation from Account Admin

#### 3. Databricks Workspace URL
```
AWS:   https://your-workspace.cloud.databricks.com
Azure: https://adb-<workspace-id>.<random>.azuredatabricks.net
GCP:   https://<workspace-id>.gcp.databricks.com
```

#### 4. Account API Configuration (Optional)

**Only configure if you need Account-level operations:**

Account API enables:
- Multi-workspace management
- User and group administration
- Workspace creation/deletion
- Account-level permissions

**Required Information:**
- `DATABRICKS_ACCOUNT_ID`: Account ID (UUID format)
- `DATABRICKS_ACCOUNT_HOST`:
  - AWS/GCP: `https://accounts.cloud.databricks.com`
  - Azure: `https://accounts.azuredatabricks.net`

**How to Find Account ID:**
1. Access Databricks Account Console
2. Top-right profile â†’ Account Settings
3. Copy Account ID

**Permission Requirements:**
- Account Admin role required
- Or Service Principal with Account Admin permissions

**ğŸ’¡ Tip**: Skip this if you only need Workspace-level operations.

---

### 1. Claude Desktop (EN)

Claude Desktop is Anthropic's official desktop application with the easiest MCP server setup.

#### 1.1 Configuration File Location

**macOS:**
```bash
~/Library/Application Support/Claude/claude_desktop_config.json
```

**Windows:**
```
%APPDATA%\Claude\claude_desktop_config.json
```

#### 1.2 Open Configuration File

**Method 1: Using Claude Desktop UI**
1. Launch Claude Desktop
2. Open Settings
3. Select Developer tab
4. Click "Edit Config" button

**Method 2: Direct File Edit**
```bash
# macOS
open ~/Library/Application\ Support/Claude/claude_desktop_config.json

# Windows (Notepad)
notepad %APPDATA%\Claude\claude_desktop_config.json
```

#### 1.3 Basic Configuration (OAuth)

```json
{
  "mcpServers": {
    "databricks": {
      "command": "uvx",
      "args": ["databricks-mcp"],
      "env": {
        "DATABRICKS_HOST": "https://your-workspace.cloud.databricks.com",
        "DATABRICKS_AUTH_TYPE": "oauth-u2m"
      }
    }
  }
}
```

#### 1.4 PAT Configuration

```json
{
  "mcpServers": {
    "databricks": {
      "command": "uvx",
      "args": ["databricks-mcp"],
      "env": {
        "DATABRICKS_HOST": "https://your-workspace.cloud.databricks.com",
        "DATABRICKS_TOKEN": "dapi1234567890abcdef..."
      }
    }
  }
}
```

#### 1.5 Service Principal Configuration (Production)

```json
{
  "mcpServers": {
    "databricks": {
      "command": "uvx",
      "args": ["databricks-mcp"],
      "env": {
        "DATABRICKS_HOST": "https://your-workspace.cloud.databricks.com",
        "DATABRICKS_CLIENT_ID": "your-service-principal-client-id",
        "DATABRICKS_CLIENT_SECRET": "your-service-principal-secret"
      }
    }
  }
}
```

#### 1.6 Multiple Workspaces Configuration

```json
{
  "mcpServers": {
    "databricks-prod": {
      "command": "uvx",
      "args": ["databricks-mcp"],
      "env": {
        "DATABRICKS_HOST": "https://prod-workspace.cloud.databricks.com",
        "DATABRICKS_TOKEN": "dapi_prod_token..."
      }
    },
    "databricks-dev": {
      "command": "uvx",
      "args": ["databricks-mcp"],
      "env": {
        "DATABRICKS_HOST": "https://dev-workspace.cloud.databricks.com",
        "DATABRICKS_AUTH_TYPE": "oauth-u2m"
      }
    }
  }
}
```

#### 1.7 Apply Configuration and Verify

1. Save configuration file
2. **Completely quit** Claude Desktop (Cmd+Q / Alt+F4)
3. Restart Claude Desktop
4. Start a new conversation
5. Check for **ğŸ”¨ icon** (MCP server indicator) at bottom of input box
6. Click icon to verify "databricks" server is active

#### 1.8 First Run (OAuth)

When using OAuth authentication:
1. On first MCP tool use, a browser window opens automatically
2. Log into Databricks
3. Click "Authorize"
4. Close browser tab
5. Return to Claude Desktop and continue

#### 1.9 Test

In Claude Desktop, try:

```
"List all my Databricks clusters"
"Show me the tables in my Unity Catalog"
"Execute this SQL: SELECT * FROM samples.nyctaxi.trips LIMIT 10"
```

---

### 2. Claude Code (CLI) (EN)

Claude Code is Anthropic's CLI tool for terminal use.

#### 2.1 Configuration File Location

**All platforms:**
```bash
~/.config/claude/config.json
```

#### 2.2 Create/Edit Configuration File

```bash
# Create directory
mkdir -p ~/.config/claude

# Edit file
nano ~/.config/claude/config.json
# or
code ~/.config/claude/config.json
# or
vim ~/.config/claude/config.json
```

#### 2.3 Basic Configuration

```json
{
  "mcpServers": {
    "databricks": {
      "command": "uvx",
      "args": ["databricks-mcp"],
      "env": {
        "DATABRICKS_HOST": "https://your-workspace.cloud.databricks.com",
        "DATABRICKS_AUTH_TYPE": "oauth-u2m"
      }
    }
  }
}
```

#### 2.4 Using .databrickscfg Profiles

If you're already using Databricks CLI, reuse existing configuration:

```json
{
  "mcpServers": {
    "databricks": {
      "command": "uvx",
      "args": ["databricks-mcp"],
      "env": {
        "DATABRICKS_CONFIG_PROFILE": "production"
      }
    }
  }
}
```

`~/.databrickscfg` file:
```ini
[production]
host = https://prod-workspace.cloud.databricks.com
token = dapi...

[development]
host = https://dev-workspace.cloud.databricks.com
auth_type = oauth-u2m
```

#### 2.5 Test

```bash
# Run Claude Code
claude

# Test in prompt
> List my Databricks clusters
> Show tables in catalog 'main'
```

---

### 3. Cursor IDE (EN)

Cursor is an AI-powered code editor.

#### 3.1 Configuration File Location

**Per-project (recommended):**
```
your-project/.cursor/mcp.json
```

**Global:**
```
~/.cursor/mcp.json
```

#### 3.2 UI-based Configuration

1. Launch Cursor
2. `Cmd+,` (macOS) or `Ctrl+,` (Windows/Linux) - Open Settings
3. Find "Developer" section
4. Click "Edit Config"
5. Select "MCP Tools"
6. Click "Add Custom MCP"

#### 3.3 Manual Configuration File Creation

**Per-project setup:**
```bash
# In project root
mkdir -p .cursor
nano .cursor/mcp.json
```

**Basic configuration:**
```json
{
  "mcpServers": {
    "databricks": {
      "command": "uvx",
      "args": ["databricks-mcp"],
      "env": {
        "DATABRICKS_HOST": "https://your-workspace.cloud.databricks.com",
        "DATABRICKS_AUTH_TYPE": "oauth-u2m"
      }
    }
  }
}
```

#### 3.4 Environment Variables (Sensitive Data)

To avoid storing tokens directly in config:

```json
{
  "mcpServers": {
    "databricks": {
      "command": "uvx",
      "args": ["databricks-mcp"],
      "env": {
        "DATABRICKS_HOST": "https://your-workspace.cloud.databricks.com",
        "DATABRICKS_TOKEN": "${DATABRICKS_TOKEN}"
      }
    }
  }
}
```

Then set environment variable:
```bash
# ~/.bashrc or ~/.zshrc
export DATABRICKS_TOKEN="dapi..."
```

#### 3.5 One-Click Install (Cursor Built-in)

Latest Cursor versions provide an MCP server marketplace:

1. In Cursor, press `Cmd+K` (Open AI chat)
2. Click MCP icon
3. Select "Browse MCP Servers"
4. Search for "databricks-mcp"
5. Click "Install" (if available)

#### 3.6 Important Limitation

âš ï¸ **Cursor currently only sends the first 40 tools to the Agent.**

Since Databricks MCP provides 82 tools, you may need to enable/disable servers as needed.

#### 3.7 Verify Configuration

1. Restart Cursor
2. Open AI chat (`Cmd+K`)
3. Check for MCP icon (green when active)
4. Test prompt:
```
@databricks list my clusters
```

---

### 4. Cline (VS Code Extension)

Cline is a powerful AI coding assistant for VS Code.

#### 4.1 Install Cline

1. Open VS Code
2. Open Extensions panel (`Cmd+Shift+X`)
3. Search "Cline"
4. Click "Install"

#### 4.2 Access MCP Server Configuration

**Method 1: Using Cline UI**
1. Open Cline panel in VS Code
2. Click "MCP Servers" icon in top navigation
3. Select "Installed" tab
4. Click "Configure MCP Servers" button at bottom

**Method 2: Direct File Edit**
```bash
# VS Code settings directory
code ~/.vscode/extensions/cline/mcp_settings.json
```

#### 4.3 Basic Configuration

```json
{
  "mcpServers": {
    "databricks": {
      "command": "uvx",
      "args": ["databricks-mcp"],
      "env": {
        "DATABRICKS_HOST": "https://your-workspace.cloud.databricks.com",
        "DATABRICKS_AUTH_TYPE": "oauth-u2m"
      },
      "disabled": false,
      "alwaysAllow": []
    }
  }
}
```

#### 4.4 Auto-Approve Configuration

To automatically approve specific tools:

```json
{
  "mcpServers": {
    "databricks": {
      "command": "uvx",
      "args": ["databricks-mcp"],
      "env": {
        "DATABRICKS_HOST": "https://your-workspace.cloud.databricks.com",
        "DATABRICKS_TOKEN": "dapi..."
      },
      "disabled": false,
      "alwaysAllow": [
        "list_clusters",
        "get_cluster",
        "list_jobs",
        "list_tables"
      ]
    }
  }
}
```

#### 4.5 Transport Types

Cline supports two transport methods:

**STDIO (Local process):**
```json
{
  "mcpServers": {
    "databricks": {
      "command": "uvx",
      "args": ["databricks-mcp"],
      "env": { ... }
    }
  }
}
```

**SSE (Remote HTTP):**
```json
{
  "mcpServers": {
    "databricks-remote": {
      "url": "https://your-mcp-server.com/sse",
      "headers": {
        "Authorization": "Bearer your-token"
      }
    }
  }
}
```

#### 4.6 Multiple Workspaces

```json
{
  "mcpServers": {
    "databricks-production": {
      "command": "uvx",
      "args": ["databricks-mcp"],
      "env": {
        "DATABRICKS_HOST": "https://prod.cloud.databricks.com",
        "DATABRICKS_TOKEN": "dapi_prod..."
      },
      "disabled": false
    },
    "databricks-staging": {
      "command": "uvx",
      "args": ["databricks-mcp"],
      "env": {
        "DATABRICKS_HOST": "https://staging.cloud.databricks.com",
        "DATABRICKS_TOKEN": "dapi_staging..."
      },
      "disabled": true
    }
  }
}
```

#### 4.7 Verify Configuration

1. Restart VS Code or reload Cline
2. Click MCP Servers icon in Cline panel
3. Verify "databricks" server is enabled
4. Check for green status indicator

#### 4.8 Test

In Cline chat:
```
Can you list all my Databricks clusters using the MCP server?
Show me tables in the 'main' catalog
```

---

### 5. Continue (VS Code Extension)

Continue is a VS Code AI coding assistant supporting multiple LLMs.

#### 5.1 Install Continue

1. Open VS Code
2. Extensions panel (`Cmd+Shift+X`)
3. Search "Continue"
4. Click "Install"

#### 5.2 Configuration File Location

**Per-workspace:**
```
.continue/mcpServers/
```

**Global:**
```
~/.continue/mcpServers/
```

#### 5.3 Create Configuration File

**In workspace:**
```bash
# In project root
mkdir -p .continue/mcpServers
cd .continue/mcpServers
```

**Create YAML format:**
```bash
nano databricks-mcp.yaml
```

#### 5.4 YAML Configuration Example

```yaml
mcpServers:
  - name: Databricks MCP
    command: uvx
    args:
      - databricks-mcp
    env:
      DATABRICKS_HOST: https://your-workspace.cloud.databricks.com
      DATABRICKS_AUTH_TYPE: oauth-u2m
```

#### 5.5 JSON Configuration Example (Alternative)

You can reuse configuration from Claude Desktop or Cursor:

```bash
# Copy Claude Desktop config
cp ~/Library/Application\ Support/Claude/claude_desktop_config.json \
   .continue/mcpServers/databricks.json
```

Or create directly:
```json
{
  "mcpServers": {
    "databricks": {
      "command": "uvx",
      "args": ["databricks-mcp"],
      "env": {
        "DATABRICKS_HOST": "https://your-workspace.cloud.databricks.com",
        "DATABRICKS_TOKEN": "dapi..."
      }
    }
  }
}
```

#### 5.6 Complex Configuration Example

```yaml
mcpServers:
  - name: Databricks Production
    command: uvx
    args:
      - databricks-mcp
    env:
      DATABRICKS_HOST: https://prod-workspace.cloud.databricks.com
      DATABRICKS_CLIENT_ID: ${DATABRICKS_PROD_CLIENT_ID}
      DATABRICKS_CLIENT_SECRET: ${DATABRICKS_PROD_CLIENT_SECRET}

  - name: Databricks Development
    command: uvx
    args:
      - databricks-mcp
    env:
      DATABRICKS_HOST: https://dev-workspace.cloud.databricks.com
      DATABRICKS_AUTH_TYPE: oauth-u2m
```

#### 5.7 Remote MCP Server Configuration

Continue also supports HTTP-based remote servers:

```yaml
mcpServers:
  - name: Databricks Remote
    transport: streamable-http
    url: https://your-mcp-server.com/mcp
    headers:
      Authorization: Bearer ${MCP_TOKEN}
```

#### 5.8 Verify Configuration

1. Restart VS Code
2. Open Continue panel
3. Click settings icon
4. Check "MCP Servers" section
5. Verify "databricks" server shows as connected

#### 5.9 Test

In Continue chat:
```
@databricks list my clusters
@databricks show tables in main.default
```

---

### 6. Zed Editor (EN)

Zed is a high-performance collaborative code editor.

#### 6.1 Access Configuration File

**Method 1: Using Zed UI**
1. Open Zed
2. `Cmd+,` (Open settings)
3. Click "Preferences" > "Settings"
4. JSON editor opens

**Method 2: Direct File Edit**
```bash
# macOS/Linux
~/.config/zed/settings.json

# Open
code ~/.config/zed/settings.json
```

#### 6.2 Install MCP Extension (Easy Way)

1. Open Agent panel in Zed
2. Click top-right menu
3. Select "View Server Extensions"
4. Search "databricks" (if community extension available)
5. Click "Install"

#### 6.3 Manual Configuration

Add to `settings.json`:

```json
{
  "context_servers": {
    "databricks": {
      "settings": {},
      "command": {
        "path": "uvx",
        "args": ["databricks-mcp"],
        "env": {
          "DATABRICKS_HOST": "https://your-workspace.cloud.databricks.com",
          "DATABRICKS_AUTH_TYPE": "oauth-u2m"
        }
      }
    }
  }
}
```

#### 6.4 Complete Configuration Example

```json
{
  "context_servers": {
    "databricks-production": {
      "settings": {
        "description": "Production Databricks workspace"
      },
      "command": {
        "path": "uvx",
        "args": ["databricks-mcp"],
        "env": {
          "DATABRICKS_HOST": "https://prod.cloud.databricks.com",
          "DATABRICKS_TOKEN": "dapi_prod_token"
        }
      }
    },
    "databricks-development": {
      "settings": {
        "description": "Development Databricks workspace"
      },
      "command": {
        "path": "uvx",
        "args": ["databricks-mcp"],
        "env": {
          "DATABRICKS_HOST": "https://dev.cloud.databricks.com",
          "DATABRICKS_AUTH_TYPE": "oauth-u2m"
        }
      }
    }
  }
}
```

#### 6.5 Enable Tools

1. Save configuration file
2. Restart Zed
3. Open Agent panel
4. Select "Configure profiles"
5. Select "databricks" profile
6. Click "Configure MCP Tools"
7. Choose tools to enable

#### 6.6 Verify Server Status

1. Open Agent panel settings view
2. Check indicator next to MCP server name:
   - ğŸŸ¢ Green dot = "Server is active" (working)
   - ğŸ”´ Red dot = "Server error" (error)
   - âšª Gray dot = "Server inactive" (inactive)

#### 6.7 Current Limitations (2025)

âš ï¸ **Zed MCP Support Limitations:**
- Latest MCP spec (2025-06-18) not fully supported yet
- HTTP streaming not supported (stdio only)
- Only prompts supported (shown as slash commands)
- Multiple prompt arguments not supported

#### 6.8 Test

In Zed Agent:
```
/databricks-prompt list-clusters
```

Or natural language:
```
Show me all my Databricks clusters
List tables in the main catalog
```

---

### 7. Windsurf IDE (EN)

Windsurf is an AI-powered IDE developed by Codeium.

#### 7.1 Configuration File Location

```
~/.codeium/windsurf/mcp_config.json
```

#### 7.2 UI-based Configuration

**Method 1: Settings Menu**
1. Open Windsurf
2. Settings > Advanced Settings
3. Scroll to "Cascade" section
4. Click "Add New Server"
5. Enter server information

**Method 2: Command Palette**
1. `Cmd+Shift+P` (macOS) or `Ctrl+Shift+P` (Windows/Linux)
2. Type "Open Windsurf Settings Page"
3. Find "Cascade" > "MCP Servers" section
4. Click "Add Custom Server +"

**Method 3: Cascade Toolbar**
1. Open Cascade in Windsurf
2. Click ğŸ”¨ (Hammer) icon in toolbar
3. Click "Configure" button

#### 7.3 Basic Configuration

```json
{
  "mcpServers": {
    "databricks": {
      "command": "uvx",
      "args": ["databricks-mcp"],
      "env": {
        "DATABRICKS_HOST": "https://your-workspace.cloud.databricks.com",
        "DATABRICKS_AUTH_TYPE": "oauth-u2m"
      },
      "disabled": false,
      "alwaysAllow": []
    }
  }
}
```

#### 7.4 Local Server Configuration (Node.js)

For locally built MCP servers:

```json
{
  "mcpServers": {
    "databricks": {
      "command": "node",
      "args": ["/path/to/databricks-mcp/build/index.js"],
      "env": {
        "DATABRICKS_HOST": "https://your-workspace.cloud.databricks.com",
        "DATABRICKS_TOKEN": "dapi..."
      },
      "disabled": false
    }
  }
}
```

#### 7.5 Docker-based Configuration

Using Docker:

```json
{
  "mcpServers": {
    "databricks": {
      "command": "docker",
      "args": [
        "run",
        "-i",
        "--rm",
        "-e", "DATABRICKS_HOST",
        "-e", "DATABRICKS_TOKEN",
        "your-dockerhub-username/databricks-mcp"
      ],
      "env": {
        "DATABRICKS_HOST": "https://your-workspace.cloud.databricks.com",
        "DATABRICKS_TOKEN": "dapi..."
      }
    }
  }
}
```

#### 7.6 Remote MCP Server Configuration

For remotely hosted MCP servers:

```json
{
  "mcpServers": {
    "databricks-remote": {
      "command": "npx",
      "args": [
        "mcp-remote",
        "https://your-mcp-server.com/sse"
      ],
      "env": {
        "MCP_TOKEN": "your-auth-token"
      }
    }
  }
}
```

#### 7.7 Multiple Environments

```json
{
  "mcpServers": {
    "databricks-production": {
      "command": "uvx",
      "args": ["databricks-mcp"],
      "env": {
        "DATABRICKS_HOST": "https://prod.cloud.databricks.com",
        "DATABRICKS_CLIENT_ID": "prod-client-id",
        "DATABRICKS_CLIENT_SECRET": "prod-secret"
      },
      "disabled": false,
      "alwaysAllow": ["list_clusters", "list_jobs"]
    },
    "databricks-staging": {
      "command": "uvx",
      "args": ["databricks-mcp"],
      "env": {
        "DATABRICKS_HOST": "https://staging.cloud.databricks.com",
        "DATABRICKS_TOKEN": "dapi_staging..."
      },
      "disabled": false
    },
    "databricks-development": {
      "command": "uvx",
      "args": ["databricks-mcp"],
      "env": {
        "DATABRICKS_HOST": "https://dev.cloud.databricks.com",
        "DATABRICKS_AUTH_TYPE": "oauth-u2m"
      },
      "disabled": true
    }
  }
}
```

#### 7.8 Using Pre-configured Servers

Windsurf provides popular MCP servers pre-configured:

1. Click Plugins icon in Windsurf sidebar
2. Select "MCP Servers" tab
3. View available servers list
4. Find "databricks-mcp" (if available)
5. Click "Install" or "Enable"

#### 7.9 Verify Configuration

1. Restart Windsurf
2. Open Cascade panel
3. Click ğŸ”¨ icon to view MCP tools list
4. Verify "databricks" server is connected
5. Check available tools list

#### 7.10 Test

In Cascade:
```
@databricks list all my clusters
@databricks show me tables in the main catalog
@databricks execute SQL: SELECT * FROM samples.nyctaxi.trips LIMIT 5
```

---

### 8. OpenAI Codex (CLI) (EN)

OpenAI Codex is a lightweight coding agent that runs in your terminal with full MCP server support.

#### 8.1 Install Codex

```bash
# Install via npm
npm install -g @openai/codex

# Or run directly
npx @openai/codex
```

#### 8.2 Configuration File Location

```
~/.codex/config.toml
```

#### 8.3 Add MCP Server

**Via command line:**
```bash
codex mcp add databricks \
  --env DATABRICKS_HOST=https://your-workspace.cloud.databricks.com \
  --env DATABRICKS_AUTH_TYPE=oauth-u2m \
  -- uvx databricks-mcp
```

**Using PAT:**
```bash
codex mcp add databricks \
  --env DATABRICKS_HOST=https://your-workspace.cloud.databricks.com \
  --env DATABRICKS_TOKEN=dapi... \
  -- uvx databricks-mcp
```

**Using Service Principal:**
```bash
codex mcp add databricks \
  --env DATABRICKS_HOST=https://your-workspace.cloud.databricks.com \
  --env DATABRICKS_CLIENT_ID=your-client-id \
  --env DATABRICKS_CLIENT_SECRET=your-secret \
  -- uvx databricks-mcp
```

#### 8.4 Manual Configuration (config.toml)

```bash
# Edit configuration file
nano ~/.codex/config.toml
```

**Basic configuration:**
```toml
[[mcp_servers]]
name = "databricks"
command = "uvx"
args = ["databricks-mcp"]

[mcp_servers.env]
DATABRICKS_HOST = "https://your-workspace.cloud.databricks.com"
DATABRICKS_AUTH_TYPE = "oauth-u2m"
```

**Multiple workspaces:**
```toml
[[mcp_servers]]
name = "databricks-prod"
command = "uvx"
args = ["databricks-mcp"]

[mcp_servers.env]
DATABRICKS_HOST = "https://prod-workspace.cloud.databricks.com"
DATABRICKS_TOKEN = "dapi_prod..."

[[mcp_servers]]
name = "databricks-dev"
command = "uvx"
args = ["databricks-mcp"]

[mcp_servers.env]
DATABRICKS_HOST = "https://dev-workspace.cloud.databricks.com"
DATABRICKS_AUTH_TYPE = "oauth-u2m"
```

#### 8.5 View MCP Server List

```bash
# In Codex TUI
codex

# Inside TUI
/mcp
```

This displays your actively connected MCP servers.

#### 8.6 Manage MCP Servers

**Remove server:**
```bash
codex mcp remove databricks
```

**List servers:**
```bash
codex mcp list
```

#### 8.7 Use Codex as MCP Server

You can also run Codex itself as an MCP server:

```bash
# Start Codex as MCP server
codex mcp-server

# Test with MCP Inspector
npx @modelcontextprotocol/inspector codex mcp-server
```

#### 8.8 Docker MCP Toolkit

Access 220+ MCP servers securely through Docker MCP Toolkit:

```bash
# Install Docker MCP Toolkit
npm install -g @docker/mcp-toolkit

# Add Databricks MCP server
docker-mcp add databricks
```

#### 8.9 Test

In Codex TUI:
```bash
# Start Codex
codex

# In prompt
> List all my Databricks clusters
> Show tables in catalog 'main'
> Execute SQL: SELECT * FROM samples.nyctaxi.trips LIMIT 5
```

#### 8.10 Integration with OpenAI Agents SDK

Use Codex with OpenAI Agents SDK:

```python
from openai import OpenAI
from codex_mcp import CodexMCPServer

# Initialize Codex as MCP server
server = CodexMCPServer()

# Use in Agent
client = OpenAI()
response = client.chat.completions.create(
    model="gpt-4",
    messages=[
        {"role": "user", "content": "List my Databricks clusters"}
    ],
    tools=server.get_tools()
)
```

---

### 9. Dify (EN)

Dify is an LLMOps platform with two-way MCP support since v1.6.0.

#### 9.1 MCP Support in Dify

Dify supports MCP in two ways:
1. **Consume MCP tools in Dify** (MCP client)
2. **Publish Dify apps as MCP servers** (MCP server)

#### 9.2 Add MCP Server (Use in Dify)

**Method 1: Via Dify UI**

1. Log into Dify workspace
2. Navigate to **Tools** page
3. Select **MCP** section
4. Click **Add Server**
5. Enter server information:

```json
{
  "name": "databricks",
  "type": "stdio",
  "command": "uvx",
  "args": ["databricks-mcp"],
  "env": {
    "DATABRICKS_HOST": "https://your-workspace.cloud.databricks.com",
    "DATABRICKS_AUTH_TYPE": "oauth-u2m"
  }
}
```

**Method 2: Environment Variables**

Set directly in Dify server environment:

```bash
export DIFY_MCP_SERVERS='[
  {
    "name": "databricks",
    "command": "uvx",
    "args": ["databricks-mcp"],
    "env": {
      "DATABRICKS_HOST": "https://your-workspace.cloud.databricks.com",
      "DATABRICKS_TOKEN": "dapi..."
    }
  }
]'
```

#### 9.3 Use in Agent Workflows

**1. Create Agent Node:**
- Add **Agent** node in Workflow
- Select **databricks** in MCP Tools section
- Choose tools to use:
  - `list_clusters`
  - `execute_sql`
  - `list_tables`
  - etc.

**2. Agent automatically calls tools:**
```
User: "Show me all running clusters"
â†’ Agent automatically calls list_clusters tool
â†’ Returns results
```

#### 9.4 Use as Workflow Nodes

**Add individual MCP tools as nodes:**

1. Open Workflow editor
2. Click **Add Node**
3. Select **MCP Tool** category
4. Choose **databricks** > **execute_sql**
5. Set parameters:
   ```json
   {
     "warehouse_id": "{{warehouse_id}}",
     "sql": "SELECT * FROM main.default.my_table"
   }
   ```

This approach provides explicit call ordering without LLM decisions.

#### 9.5 Publish Dify Apps as MCP Servers

Expose Dify workflows as MCP servers for use in Claude, Cursor, etc:

**1. Prepare Workflow:**

For all input parameters in Start node:
- **Parameter Name**: Clear name (e.g., `cluster_name`, `sql_query`)
- **Parameter Description**: Detailed description
  ```
  Example: "The name of the Databricks cluster to query"
  ```

**2. Write Service Description:**

In workflow settings:
```
Service Description: "Query Databricks clusters and execute SQL through a Dify workflow"
```

**3. Generate MCP Server URL:**

- After setup, Dify issues MCP server URL
- Example: `https://your-dify.com/mcp/v1/workflows/abc123`

**4. Use in Claude Desktop:**

```json
{
  "mcpServers": {
    "dify-databricks": {
      "url": "https://your-dify.com/mcp/v1/workflows/abc123",
      "headers": {
        "Authorization": "Bearer YOUR_DIFY_API_KEY"
      }
    }
  }
}
```

**5. Use in Cursor:**

`.cursor/mcp.json`:
```json
{
  "mcpServers": {
    "dify-databricks": {
      "url": "https://your-dify.com/mcp/v1/workflows/abc123",
      "headers": {
        "Authorization": "Bearer YOUR_DIFY_API_KEY"
      }
    }
  }
}
```

#### 9.6 Zapier/Composio Integration

Dify MCP provides access to 8,000+ apps through Zapier and Composio:

**Add Zapier MCP:**
1. Select **MCP** on Tools page
2. Add **Zapier** server
3. Enter Zapier API key
4. Select Zapier Actions to use

**Usage example:**
```
"Query data from Databricks and save results to Google Sheets"
â†’ Get data with Databricks MCP
â†’ Write to Google Sheets with Zapier MCP
```

#### 9.7 Community MCP Server (dify-mcp-server)

Use third-party MCP server to call Dify workflows:

**Installation:**
```bash
npm install -g dify-mcp-server
```

**Configuration:**
```yaml
# config.yaml
dify:
  base_url: https://your-dify.com
  app_sks:
    - app-abc123-secret-key-1
    - app-def456-secret-key-2
```

**Run:**
```bash
dify-mcp-server --config config.yaml
```

**Claude Desktop configuration:**
```json
{
  "mcpServers": {
    "dify": {
      "command": "dify-mcp-server",
      "args": ["--config", "/path/to/config.yaml"]
    }
  }
}
```

#### 9.8 Verify Configuration

**Check MCP server status:**
1. Open Dify Tools page
2. Check connection status in MCP section
3. Green indicator = connected

**Test tools:**
1. Create Agent node in Workflow
2. Request "List my Databricks clusters"
3. Verify Agent calls MCP tools

#### 9.9 Advanced Configuration

**Multiple Databricks workspaces:**

```json
[
  {
    "name": "databricks-prod",
    "command": "uvx",
    "args": ["databricks-mcp"],
    "env": {
      "DATABRICKS_HOST": "https://prod.cloud.databricks.com",
      "DATABRICKS_TOKEN": "dapi_prod..."
    }
  },
  {
    "name": "databricks-dev",
    "command": "uvx",
    "args": ["databricks-mcp"],
    "env": {
      "DATABRICKS_HOST": "https://dev.cloud.databricks.com",
      "DATABRICKS_AUTH_TYPE": "oauth-u2m"
    }
  }
]
```

**Permission settings:**
- Add MCP servers with Dify Admin rights
- Grant tool usage permissions to team members
- Manage API keys separately

#### 9.10 Test

**In Agent workflow:**
```
User: "What clusters are running in my Databricks workspace?"
â†’ Dify Agent calls databricks MCP server
â†’ Uses list_clusters tool
â†’ Returns results formatted in natural language
```

**As workflow nodes:**
```
[Start] â†’ [MCP: list_clusters] â†’ [LLM: Analyze results] â†’ [End]
```

---

### 10. n8n (EN)

n8n is a workflow automation platform with bidirectional MCP support (both client and server).

#### 10.1 n8n MCP Support Overview

n8n supports MCP in two ways:
1. **MCP Client**: Call external MCP server tools from n8n
2. **MCP Server**: Expose n8n workflows as MCP servers

#### 10.2 Install n8n

```bash
# Global installation via npm
npm install -g n8n

# Using Docker
docker run -it --rm --name n8n -p 5678:5678 n8nio/n8n

# Run directly with npx
npx n8n
```

#### 10.3 Using MCP Client Tool Node

Call Databricks MCP server from n8n:

**1. Create Workflow:**
1. Click "New Workflow" in n8n dashboard
2. Add node â†’ "AI" category
3. Select "MCP Client Tool" node

**2. Configure MCP Server Connection:**

In node settings:
```json
{
  "transport": "stdio",
  "command": "uvx",
  "args": ["databricks-mcp"],
  "env": {
    "DATABRICKS_HOST": "https://your-workspace.cloud.databricks.com",
    "DATABRICKS_AUTH_TYPE": "oauth-u2m"
  }
}
```

**3. HTTP Streamable Transport:**

For remote MCP servers:
```json
{
  "transport": "http-streamable",
  "url": "https://your-mcp-server.com/mcp",
  "headers": {
    "Authorization": "Bearer YOUR_TOKEN"
  }
}
```

#### 10.4 Using MCP Tools in Agent

**Configure AI Agent Node:**

1. **Add Agent Node**:
   - "AI" â†’ "AI Agent" node
   - Select Model (OpenAI, Anthropic, etc.)

2. **Connect MCP Tools**:
   - Add "MCP Client Tool" in Tools section
   - Configure Databricks MCP server

3. **Example Prompt**:
```
Input: "List all running Databricks clusters and their current state"
â†’ Agent automatically calls list_clusters MCP tool
â†’ Analyzes and responds with results
```

#### 10.5 Expose n8n as MCP Server

Make n8n workflows available to Claude, Cursor, etc:

**1. Use MCP Server Trigger Node:**

1. Create new workflow
2. Add "MCP Server Trigger" node
3. Enter tool name and description:
   ```
   Tool Name: query_databricks
   Description: Execute SQL queries on Databricks and format results
   ```

4. Define parameters:
   ```json
   {
     "sql": {
       "type": "string",
       "description": "SQL query to execute",
       "required": true
     },
     "warehouse_id": {
       "type": "string",
       "description": "SQL Warehouse ID"
     }
   }
   ```

5. Build workflow logic:
   - HTTP Request node to call Databricks API
   - Process and format results
   - Return node to send results back

**2. n8n MCP Server URL:**

After activating workflow, get MCP server URL:
```
http://localhost:5678/mcp/workflows/<workflow-id>
```

**3. Use n8n MCP Server in Claude Desktop:**

```json
{
  "mcpServers": {
    "n8n-databricks": {
      "url": "http://localhost:5678/mcp/workflows/<workflow-id>",
      "headers": {
        "Authorization": "Bearer YOUR_N8N_API_KEY"
      }
    }
  }
}
```

#### 10.6 Community Node

**Install n8n-nodes-mcp:**

```bash
# Install from n8n Community Nodes
cd ~/.n8n
npm install n8n-nodes-mcp
```

This custom node supports:
- âœ… HTTP Streamable transport
- âœ… SSE (Server-Sent Events)
- âœ… Command-line transport
- âœ… Bearer & generic header authentication

#### 10.7 Real-World Example: Databricks Automation

**Automation Scenario: Daily Cluster Health Monitoring**

```
[Schedule Trigger: Daily 9 AM]
  â†“
[MCP Client Tool: list_clusters]
  â†“
[Code: Filter running clusters]
  â†“
[IF: Any cluster issues?]
  â†“ Yes
[Slack: Send alert]
  â†“ No
[Email: Daily report]
```

**Workflow Configuration:**

1. **Schedule Trigger** - Daily at 9 AM
2. **MCP Client Tool** - Call Databricks MCP server
3. **Code Node** - Analyze cluster states
4. **IF Node** - Detect issues
5. **Slack/Email** - Send notifications

#### 10.8 Environment Variables

Configure environment variables in n8n:

**When starting n8n server:**
```bash
export N8N_MCP_DATABRICKS_HOST="https://your-workspace.cloud.databricks.com"
export N8N_MCP_DATABRICKS_TOKEN="dapi..."

n8n start
```

**Docker Compose:**
```yaml
version: '3.8'
services:
  n8n:
    image: n8nio/n8n
    ports:
      - "5678:5678"
    environment:
      - N8N_MCP_DATABRICKS_HOST=https://your-workspace.cloud.databricks.com
      - N8N_MCP_DATABRICKS_TOKEN=dapi...
    volumes:
      - n8n_data:/home/node/.n8n
```

#### 10.9 Account API Configuration

For Account-level operations:

```json
{
  "transport": "stdio",
  "command": "uvx",
  "args": ["databricks-mcp"],
  "env": {
    "DATABRICKS_HOST": "https://your-workspace.cloud.databricks.com",
    "DATABRICKS_AUTH_TYPE": "oauth-u2m",
    "DATABRICKS_ACCOUNT_ID": "your-account-id",
    "DATABRICKS_ACCOUNT_HOST": "https://accounts.cloud.databricks.com"
  }
}
```

#### 10.10 Test

**Simple Test Workflow:**

1. Add Manual Trigger node
2. Add MCP Client Tool node (configure Databricks)
3. Tool: `list_clusters`
4. Parameters: `{}`
5. Execute workflow â†’ View cluster list

---

### Troubleshooting (English)

#### Common Issues

##### 1. "uvx: command not found" Error

**Solution:**
```bash
# Install uv
# macOS/Linux
curl -LsSf https://astral.sh/uv/install.sh | sh

# Windows
powershell -c "irm https://astral.sh/uv/install.ps1 | iex"

# Verify installation
uvx --version
```

**Alternative: Use pip**
```json
{
  "mcpServers": {
    "databricks": {
      "command": "python",
      "args": ["-m", "databricks_mcp"],
      "env": { ... }
    }
  }
}
```

##### 2. "Could not connect to Databricks" Error

**Check:**
1. DATABRICKS_HOST is correct (no trailing slash)
2. Network connectivity
3. Workspace URL is valid

```json
// âŒ Wrong
"DATABRICKS_HOST": "https://your-workspace.cloud.databricks.com/"

// âœ… Correct
"DATABRICKS_HOST": "https://your-workspace.cloud.databricks.com"
```

##### 3. "Authentication failed" Error

**Using OAuth:**
- Check if browser opens automatically
- Disable popup blockers
- Verify logging in with correct account

**Using PAT:**
- Check token hasn't expired
- Verify token copied correctly (no spaces)
- Ensure token has necessary permissions

**Using Service Principal:**
- Verify Client ID and Secret are correct
- Check Service Principal added to workspace
- Ensure necessary permissions granted

##### 4. MCP Server Icon Not Visible

**Solution:**
1. Completely quit client application
2. Check JSON syntax in config file (commas, brackets)
3. Restart client
4. Check logs (see client-specific log locations)

##### 5. Only Some Tools Working

**Causes:**
- Insufficient permissions
- Required Databricks features not enabled
- Workspace tier limitations

**Solution:**
1. Check user permissions in Databricks
2. Verify necessary features enabled (Unity Catalog, MLflow, etc.)
3. Contact workspace administrator

##### 6. Slow Performance

**Optimization:**
- Disable unused MCP servers
- Use alwaysAllow list for frequently used tools
- Cache tokens locally (OAuth)

#### Client-Specific Issues

##### Claude Desktop

**Issue:** Server not connecting
```bash
# Check logs
# macOS
tail -f ~/Library/Logs/Claude/mcp*.log

# Windows
type %APPDATA%\Claude\logs\mcp*.log
```

##### Cursor

**Issue:** 40 tool limit
- Consider writing custom wrapper with only needed functions
- Split functionality across multiple MCP server instances

##### Cline / Continue

**Issue:** Tool approval prompts keep appearing
- Add frequently used tools to `alwaysAllow` list

##### Zed

**Issue:** Only prompts showing
- Zed's current MCP support is limited
- Direct tool calls planned for future updates

##### Windsurf

**Issue:** Docker container won't start
- Check Docker Desktop is running
- Verify image built correctly
- Check logs: `docker logs <container-id>`

#### Debugging Tips

##### 1. Enable Verbose Logging

Add environment variables:
```json
{
  "env": {
    "DATABRICKS_HOST": "...",
    "DATABRICKS_DEBUG": "true",
    "DATABRICKS_LOG_LEVEL": "DEBUG"
  }
}
```

##### 2. Test MCP Server Manually

```bash
# Run server directly
uvx databricks-mcp

# Run with environment variables
DATABRICKS_HOST=https://your-workspace.cloud.databricks.com \
DATABRICKS_AUTH_TYPE=oauth-u2m \
uvx databricks-mcp
```

##### 3. Test Connection with Databricks CLI

```bash
# Install Databricks CLI
pip install databricks-cli

# Test connection
databricks workspace list
```

##### 4. Network Test

```bash
# Check workspace reachable
curl -I https://your-workspace.cloud.databricks.com

# Test API endpoint
curl -H "Authorization: Bearer dapi..." \
  https://your-workspace.cloud.databricks.com/api/2.0/clusters/list
```

#### Getting Help

If issues persist:

1. **GitHub Issues**: https://github.com/YuujinHwang/databricks-mcp/issues
2. **MCP Official Docs**: https://modelcontextprotocol.io/
3. **Databricks Docs**: https://docs.databricks.com/
4. **Community Forums**:
   - Databricks Community
   - MCP Discord
   - Stack Overflow (#mcp, #databricks)

When filing issues, include:
- MCP client being used and version
- Operating system and version
- Configuration file (remove sensitive info)
- Error messages
- Log output

---

## Additional Resources

### Video Tutorials
- [MCP Setup with Claude Desktop](https://www.youtube.com/results?search_query=mcp+claude+desktop+setup) (Search YouTube)
- [Cursor MCP Configuration](https://www.youtube.com/results?search_query=cursor+mcp+setup) (Search YouTube)

### Community Examples
- [MCP Servers Collection](https://github.com/modelcontextprotocol/servers)
- [Awesome MCP Servers](https://github.com/punkpeye/awesome-mcp-servers)

### Official Documentation
- [Databricks MCP GitHub](https://github.com/YuujinHwang/databricks-mcp)
- [Model Context Protocol](https://modelcontextprotocol.io/)
- [Databricks API Reference](https://docs.databricks.com/api/workspace/introduction)

---

## Contributing to This Guide

Found an error or want to add more clients? Contributions welcome!

1. Fork the repository
2. Create a feature branch
3. Add your improvements
4. Submit a pull request

---

**Last Updated**: 2025-11-11
**Version**: 1.2.0
**Maintained by**: YuujinHwang

## Changelog

### v1.2.0 (2025-11-11)
- Added n8n workflow automation platform
- Added Account API configuration in Prerequisites
- Added Account API setup to Claude Desktop section
- Now covers 10 major MCP clients (previously 9)
- Enhanced Account-level operations documentation

### v1.1.0 (2025-11-11)
- Added OpenAI Codex (CLI) setup guide
- Added Dify platform configuration
- Now covers 9 major MCP clients (previously 7)

### v1.0.0 (2025-11-11)
- Initial release with 7 MCP clients
- Bilingual documentation (Korean/English)
